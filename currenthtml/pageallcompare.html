<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head> <body onload="start()"><style type="text/css"> .txt {   }	 #f0 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f1 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f2 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f3 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f4 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f5 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f6 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f7 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f8 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f9 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f10 { font-family:sans-serif; font-weight:normal; font-style:normal; }  #f11 { font-family:sans-serif; font-weight:normal; font-style:normal; }  #f12 { font-family:sans-serif; font-weight:normal; font-style:normal; } 	#f13 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f14 { font-family:sans-serif; font-weight:normal; font-style:normal; } #f15 { font-family:sans-serif; font-weight:normal; font-style:normal; } 	#f16 { font-family:sans-serif; font-weight:normal; font-style:normal; }	 #f17 { font-family:sans-serif; font-weight:normal; font-style:normal; } #f18 { font-family:sans-serif; font-weight:normal; font-style:normal; } #f19 { font-family:sans-serif; font-weight:normal; font-style:normal; }		#f20 { font-family:sans-serif; font-weight:normal; font-style:normal; }		</style><div style="position:absolute; left:0px; top:-20px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:0px;" width="1129" height="1542" src="page1.png">
<div class="txt" style="position:absolute; left:52px; top:51px;"><span id="f1" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1532</span></div>
<div class="txt" style="position:absolute; left:334px; top:51px;"><span id="f1" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; left:112px; top:106px;"><span id="f1" style="font-size:25px;vertical-align:baseline;color:rgba(34,30,31,1);">Fast Feature Pyramids for Object Detection</span></div>
<div class="txt" style="position:absolute; left:284px; top:182px;"><span id="f1" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">Piotr Dolla</span><span id="f2" style="font-size:16px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f1" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">r, Ron Appel, Serge Belongie, and Pietro Perona</span></div>
<div class="txt" style="position:absolute; height:209px; width:910px; left:100px; top:247px;"><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Summary—</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Multiresolution image features may be approximated via extrapolation from nearby scales, rather than being computed explicitly. This fundamental insight allows us to design object detection algorithms that are as accurate, and considerably faster, than the stateoftheart. The computational bottleneck of many modern detectors is the computation of features at every scale of a ﬁnelysampled image pyramid. Our key insight is that one may compute ﬁnely sampled feature pyramids at a fraction of the cost, without sacriﬁcing performance: for a broad family of features we ﬁnd that features computed at octavespaced scale intervals are sufﬁcient to approximate features on a ﬁnelysampled pyramid. Extrapolation is inexpensive as compared to direct feature computation. As a result, our approximation yields considerable speedups with negligible loss in detection accuracy. We modify three diverse visual recognition systems to use fast feature pyramids and show results on both pedestrian detection (measured on the Caltech, INRIA, TUDBrussels and ETH data sets) and general object detection (measured on the PASCAL VOC). The approach is general and is widely applicable to vision algorithms requiring ﬁnegrained multiscale analysis. Our approximation is valid for images with broad spectra (most natural images) and fails for images with narrow bandpass spectra (e.g., periodic textures).</span></div>










<div class="txt" style="position:absolute; left:100px; top:501px;"><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Index Terms—</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Visual features, object detection, image pyramids, pedestrian detection, natural image statistics, real-time systems</span></div>
<div class="txt" style="position:absolute; left:557px; top:530px;"><span id="f4" style="font-size:17px;vertical-align:baseline;color:rgba(34,30,31,1);">Ç</span></div>
<div class="txt" style="position:absolute; left:52px; top:582px;"><span id="f3" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">1 I</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">NTRODUCTION</span></div>
<div class="txt" style="position:absolute; left:52px; top:616px;"><span id="f5" style="font-size:27px;vertical-align:top;line-height:75%;color:rgba(34,30,31,1);">M</span><span id="f5" style="font-size:14px;vertical-align:top;color:rgba(34,30,31,1);">ULTI</span><span id="f5" style="font-size:15px;vertical-align:top;color:rgba(34,30,31,1);">-</span><span id="f5" style="font-size:14px;vertical-align:top;color:rgba(34,30,31,1);">RESOLUTION </span><span id="f5" style="font-size:15px;vertical-align:top;color:rgba(34,30,31,1);">multi-orientation decompositions</span></div>
<div class="txt" style="position:absolute; left:104px; top:640px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">are one of the foundational techniques of image anal-</span></div>
<div class="txt" style="position:absolute; height:504px; width:422px; left:52px; top:663px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ysis. The idea of analyzing image structure separately at every scale and orientation originated from a number of sources: measurements of the physiology of mammalian visual systems [1], [2], [3], principled reasoning about the statistics and coding of visual information [4], [5], [6], [7] (Gabors, DOGs, and jets), harmonic analysis [8], [9] (wavelets), and signal processing [9], [10] (multirate ﬁltering). Such representations have proven effective for visual processing tasks such as denoising [11], image enhancement [12], texture analysis [13], stereoscopic correspondence [14], motion ﬂow [15], [16], attention [17], boundary detection [18] and recognition [19], [20], [21]. <br><br>It has become clear that such representations are best at extracting visual information when they are overcomplete, i.e., when one oversamples scale, orientation and other kernel properties. This was suggested by the architecture of the primate visual system [22], where striate cortical cells (roughly equivalent to a wavelet expansion of an image) outnumber retinal ganglion cells (a representation close to image pixels) by a factor ranging from 102 to 103. Empirical studies in computer vision provide increasing evidence in favor of overcomplete representations [21], [23], [24], [25], [26]. Most likely the robustness of these representations</span></div>






















<div class="txt" style="position:absolute; height:242px; width:492px; left:52px; top:1229px;"><span id="f6" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"> </span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">P. Dolla</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">r is with the Interactive Visual Media Group at Microsoft Research, One Microsoft Way, Redmond, WA 98052. <br><br>Email: pdollar@microsoft.com.  R. Appel and P. Perona are with the Department of Electrical Engineering, California Institute of Technology, Pasadena, CA. <br><br>Email: {appel, perona}@caltech.edu.  S. Belongie is with Cornell NYC Tech and the Cornell Computer <br><br>Science Department. Manuscript received 14 Feb. 2013; revised 15 Dec. 2013; accepted 8 Jan. 2014. Date of publication 15 Jan. 2014; date of current version 10 July 2014. Recommended for acceptance by D. Forsyth. For information on obtaining reprints of this article, please send email to: reprints@ieee.org, and reference the Digital Object Identiﬁer below. Digital Object Identiﬁer no. 10.1109/TPAMI.2014.2300479</span></div>













<div class="txt" style="position:absolute; height:848px; width:429px; left:578px; top:617px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">with respect to changes in viewpoint, lighting, and image deformations is a contributing factor to their superior performance. <br><br>To understand the value of richer representations, it is instructive to examine the reasons behind the breathtaking progress in visual category detection during the past ten years. Take, for instance, pedestrian detection. Since the groundbreaking work of Viola and Jones (VJ) [27], [28], false positive rates have decreased two orders of magnitude. At 80 percent detection rate on the INRIA pedestrian data set [21], VJ outputs over 10 false positives per image (FPPI), HOG [21] outputs 1 FPPI, and more recent methods [29], [30] output well under 0.1 FPPI (data from [31], [32]). In comparing the different detection schemes one notices the representations at the front end are progressively enriched (e.g., more channels, ﬁner scale sampling, enhanced normalization schemes); this has helped fuel the dramatic improvements in detection accuracy witnessed over the course of the last decade. <br><br>Unfortunately, improved detection accuracy has been accompanied by increased computational costs. The VJ detector ran at 15 frames per second (fps) over a decade ago, on the other hand, most recent detectors require multiple seconds to process a single image as they compute richer image representations [31]. This has practical importance: in many applications of visual recognition, such as robotics, human computer interaction, automotive safety, and mobile devices, fast detection rates and low computational requirements are of the essence. <br><br>Thus, while increasing the redundancy of the representation offers improved detection and falsealarm rates, it is paid for by increased computational costs. Is this a necessary tradeoff? In this work we offer the hopedfor but surprising answer: no. <br><br>We demonstrate how to compute richer representations without paying a large computational price. How is this possible? The key insight is that natural images have fractal statistics [7], [33], [34] that we can exploit to reliably predict</span></div>





































<div class="txt" style="position:absolute; height:12px; width:708px; left:281px; top:1502px;"><span id="f1" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">01628828 </span><span id="f8" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">ß </span><span id="f1" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</span></div>

<div style="position:absolute; left:0px; top:1580px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:1600px;" width="1129" height="1542" src="page2.png">
<div class="txt" style="position:absolute; left:52px; top:1648px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:1651px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1533</span></div>
<div class="txt" style="position:absolute; height:963px; width:429px; left:52px; top:1694px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">image structure across scales. Our analysis and experiments show that this makes it possible to inexpensively estimate features at a dense set of scales by extrapolating computations carried out expensively, but infrequently, at a coarsely sampled set of scales. <br><br>Our insight leads to considerably decreased runtimes for stateoftheart object detectors that rely on rich representations, including histograms of gradients [21], with negligible impact on their detection rates. We demonstrate the effectiveness of our proposed fast feature pyramids with three distinct detection frameworks including integral channel features (ICF) [29], aggregate channel features (a novel variant of integral channel features), and deformable part models (DPM) [35]. We show results for both pedestrian detection (measured on the Caltech [31], INRIA [21], TUDBrussels [36] and ETH [37] data sets) and general object detection (measured on the PASCAL VOC [38]). Demonstrated speedups are signiﬁcant and impact on accuracy is relatively minor. <br><br>Building on our work on fast feature pyramids (ﬁrst presented in [39]), a number of systems show stateoftheart accuracy while running at frame rate on 640 Â 480 images. Aggregate channel features, described in this paper, operate at over 30 fps while achieving top results on pedestrian detection. Crosstalk cascades [40] use fast feature pyramids and couple detector evaluations of nearby windows to achieve speeds of 3565 fps. Benenson et al. [30] implemented fast feature pyramids on a GPU, and with additional innovations achieved detection rates of over 100 fps. In this work we examine and analyze feature scaling and its effect on object detection in far more detail than in our previous work [39]. <br><br>The remainder of this paper is organized as follows. We review related work in Section 2. In Section 3 we show that it is possible to create high ﬁdelity approximations of multiscale gradient histograms using gradients computed at a single scale. In Section 4 we generalize this ﬁnding to a broad family of feature types. We describe our efﬁcient scheme for computing ﬁnely sampled feature pyramids in Section 5. In Section 6 we show applications of fast feature pyramids to object detection, resulting in considerable speedups with minor loss in accuracy. We conclude in Section 7.</span></div>










































<div class="txt" style="position:absolute; left:52px; top:2714px;"><span id="f4" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">2 R</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ELATED </span><span id="f4" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">W</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ORK</span></div>
<div class="txt" style="position:absolute; height:321px; width:429px; left:52px; top:2748px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Signiﬁcant research has been devoted to scale space theory [41], including real time implementations of octave and halfoctave image pyramids [42], [43]. Sparse image pyramids often sufﬁce for certain approximations, e.g., [42] shows how to recover a disk’s characteristic scale using halfoctave pyramids. Although only loosely related, these ideas provide the intuition that ﬁnely sampled feature pyramids can perhaps be approximated. <br><br>Fast object detection has been of considerable interest in the community. Notable recent efforts for increasing detection speed include work by Felzenszwalb et al. [44] and Pedersoli et al. [45] on cascaded and coarsetoﬁne deformable part models, respectively, Lampert et al.’s [46] application of branch and bound search for detection, and Dollar et al.’s work on crosstalk cascades [40]. Cascades [27], [47],</span></div>














<div class="txt" style="position:absolute; height:619px; width:429px; left:578px; top:1694px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">[48], [49], [50], coarsetoﬁne search [51], distance transforms [52], etc., all focus on optimizing classiﬁcation speed given precomputed image features. Our work focuses on fast feature pyramid construction and is thus complementary to such approaches. <br><br>An effective framework for object detection is the sliding window paradigm [27], [53]. Top performing methods on pedestrian detection [31] and the PASCAL VOC [38] are based on sliding windows over multiscale feature pyramids [21], [29], [35]; fast feature pyramids are well suited for such sliding window detectors. Alternative detection paradigms have been proposed [54], [55], [56], [57], [58], [59]. Although a full review is outside the scope of this work, the approximations we propose could potentially be applicable to such schemes as well. <br><br>As mentioned, a number of stateoftheart detectors have recently been introduced that exploit our fast feature pyramid construction to operate at frame rate including [40] and [30]. Alternatively, parallel implementation using GPUs [60], [61], [62] can achieve fast detection while using rich representations but at the cost of added complexity and hardware requirements. Zhu et al. [63] proposed fast computation of gradient histograms using integral histograms [64]; the proposed system was real time for singlescale detection only. In scenarios such as automotive applications, real time systems have also been demonstrated [65], [66]. The insights outlined in this paper allow for real time multiscale detection in general, unconstrained settings.</span></div>



























<div class="txt" style="position:absolute; left:578px; top:2363px;"><span id="f4" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">3 M</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ULTISCALE </span><span id="f4" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">G</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">RADIENT </span><span id="f4" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">H</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ISTOGRAMS</span></div>
<div class="txt" style="position:absolute; height:321px; width:442px; left:578px; top:2398px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">We begin by exploring a simple question: </span><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">given image gradients computed at one scale, is it possible to approximate gradient histograms at a nearby scale solely from the computed gradients? If so, then we can avoid computing gradients over a ﬁnely sampled image pyramid. Intuitively, one would expect this to be possible, as signiﬁcant image structure is preserved when an image is resampled. We begin with an indepth look at a simple form of gradient histograms and develop a more general theory in Section 4. <br><br>A gradient histogram measures the distribution of the gradient angles within an image. Let Iðx; yÞ denote an m Â n discrete signal, and @I=@x and @I=@y denote the discrete derivatives of I (typically 1D centered ﬁrst differences are used). Gradient magnitude and orientation are darectnaneÀd@@Iy</span></div>














<div class="txt" style="position:absolute; height:23px; width:58px; left:661px; top:2718px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">by: </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">M</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; ði; jÞ=</span></div>


<div class="txt" style="position:absolute; height:13px; width:13px; left:709px; top:2738px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">@</span><span id="f6" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">I @x</span></div>

<div class="txt" style="position:absolute; height:23px; width:39px; left:725px; top:2741px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; jÞ2Á ¼</span></div>


<div class="txt" style="position:absolute; height:13px; width:13px; left:795px; top:2715px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">@</span><span id="f6" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">I @x</span></div>

<div class="txt" style="position:absolute; left:748px; top:2741px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">. To</span></div>
<div class="txt" style="position:absolute; height:0px; width:26px; left:811px; top:2718px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; jÞ2 þ</span></div>


<div class="txt" style="position:absolute; height:13px; width:13px; left:879px; top:2715px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">@</span><span id="f6" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">I @y</span></div>

<div class="txt" style="position:absolute; height:4px; width:26px; left:895px; top:2718px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; jÞ2</span></div>

<div class="txt" style="position:absolute; left:822px; top:2742px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">compute the</span></div>
<div class="txt" style="position:absolute; height:24px; width:104px; left:958px; top:2718px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">and </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">O</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; j</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ ¼ gradient histo</span></div>

<div class="txt" style="position:absolute; height:182px; width:455px; left:578px; top:2765px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">gram of an image, each pixel casts a vote, weighted by its gradient magnitude, for the bin corresponding to its gradient orientation. After the orientation O is quantized into Q bins so that Oði; jPÞ 2 f1; Qg, the qth bin of the histogram is deﬁned by: hq ¼ i;j Mði; jÞ1½Oði; jÞ ¼ q, where 1 is the indicator function. In the following everything that holds for global histograms also applies to local histograms (deﬁned identically except for the range of the indices i and j).</span></div>








<div class="txt" style="position:absolute; height:71px; width:377px; left:578px; top:2997px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">3.1 Gradient Histograms in Upsampled Images Intuitively the information content of an upsampled image is similar to that of the original, lowerresolution image (upsampling does not create new structure). Assume I is a</span></div>



<div style="position:absolute; left:0px; top:3130px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:3150px;" width="1129" height="1542" src="page3.png">
<div class="txt" style="position:absolute; left:52px; top:3201px;"><span id="f13" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1534</span></div>
<div class="txt" style="position:absolute; left:334px; top:3201px;"><span id="f13" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; height:128px; width:923px; left:52px; top:3717px;"><span id="f13" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 1. Behavior of gradient histograms in images resampled by a factor of two. </span><span id="f14" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">(a) Upsampling gradients</span><span id="f13" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">. Given images </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I </span><span id="f13" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">and </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">0 </span><span id="f13" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">where </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">0 denotes I upsampled by two, and corresponding gradient magnitude images M and M0, the ratio SM=SM0 should be approximately 2. The middle/bottom panels show the distribution of this ratio for gradients at ﬁxed orientation over pedestrian/natural images. In both cases the mean m % 2, as expected, and the variance is relatively small. (b) Downsampling gradients. Given images I and I0 where I0 denotes I downsampled by two, the ratio SM=SM0 % 0:34, not 0:5 as might be expected from (a) as downsampling results in loss of high frequency content. (c) Downsampling normalized gradients. Given normalized gradient magnitude images Me and Me 0, the ratio SMe =SMe 0 % 0:27. Instead of trying to derive analytical expressions governing the scaling properties of various feature types under different resampling factors, in Section 4 we describe a general law governing feature scaling.</span></div>







<div class="txt" style="position:absolute; height:73px; width:442px; left:52px; top:3893px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">continuous signal, and let </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">0 </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">denote </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">upsampled by a factor of k: I0ðx; yÞ  Iðx=k; y=kÞ. Using the deﬁnition of a derivative, one can for</span></div>



<div class="txt" style="position:absolute; height:16px; width:19px; left:82px; top:3959px;"><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">@</span><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">0 @y</span></div>

<div class="txt" style="position:absolute; height:0px; width:32px; left:99px; top:3966px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, which</span></div>

<div class="txt" style="position:absolute; left:164px; top:3943px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">show</span></div>
<div class="txt" style="position:absolute; left:215px; top:3943px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">that</span></div>
<div class="txt" style="position:absolute; height:16px; width:19px; left:253px; top:3936px;"><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">@</span><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">0 @x</span></div>

<div class="txt" style="position:absolute; height:0px; width:26px; left:273px; top:3942px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; jÞ</span></div>

<div class="txt" style="position:absolute; left:167px; top:3966px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">simply states the</span></div>
<div class="txt" style="position:absolute; left:315px; top:3942px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span></div>
<div class="txt" style="position:absolute; height:12px; width:13px; left:335px; top:3940px;"><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 k @I @x</span></div>



<div class="txt" style="position:absolute; left:362px; top:3942px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i=k;</span></div>
<div class="txt" style="position:absolute; left:403px; top:3942px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j=k</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">,</span></div>
<div class="txt" style="position:absolute; left:447px; top:3943px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">and</span></div>
<div class="txt" style="position:absolute; left:485px; top:3943px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">likewise</span></div>
<div class="txt" style="position:absolute; left:316px; top:3966px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">intuitive fact that the rate of</span></div>
<div class="txt" style="position:absolute; height:66px; width:383px; left:52px; top:3988px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">change in the upsampled image is </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">k </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">times slower the rate of change in the original image. While not exact, the above also holds approximately for interpolated discrete signals. Let M0ði; jÞ</span></div>




<div class="txt" style="position:absolute; left:153px; top:4056px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">%</span></div>
<div class="txt" style="position:absolute; height:13px; width:6px; left:173px; top:4054px;"><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 k</span></div>

<div class="txt" style="position:absolute; height:0px; width:52px; left:183px; top:4056px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">M ðdi=ke;</span></div>

<div class="txt" style="position:absolute; left:260px; top:4056px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">d</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j=k</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">eÞ</span></div>
<div class="txt" style="position:absolute; left:318px; top:4057px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">denote</span></div>
<div class="txt" style="position:absolute; height:0px; width:52px; left:383px; top:4057px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">the gradient</span></div>

<div class="txt" style="position:absolute; left:495px; top:4057px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">magni-</span></div>
<div class="txt" style="position:absolute; left:52px; top:4080px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">tude in an upsampled discrete image. Then:</span></div>
<div class="txt" style="position:absolute; left:129px; top:4124px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X </span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">kn</span></div>
<div class="txt" style="position:absolute; left:132px; top:4166px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:159px; top:4124px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X </span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">km</span></div>
<div class="txt" style="position:absolute; left:161px; top:4166px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:189px; top:4138px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">M </span><span id="f3" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">0 </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i;</span></div>
<div class="txt" style="position:absolute; height:17px; width:26px; left:236px; top:4141px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ % X kn</span></div>


<div class="txt" style="position:absolute; left:279px; top:4166px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:306px; top:4124px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X </span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">km</span></div>
<div class="txt" style="position:absolute; left:308px; top:4166px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; height:11px; width:65px; left:336px; top:4130px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1 k M ðdi=ke;</span></div>


<div class="txt" style="position:absolute; left:427px; top:4141px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">d</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j=k</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">eÞ</span></div>
<div class="txt" style="position:absolute; height:18px; width:13px; left:150px; top:4203px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ k2 Xn</span></div>


<div class="txt" style="position:absolute; left:193px; top:4228px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:220px; top:4185px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X </span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">m</span></div>
<div class="txt" style="position:absolute; left:223px; top:4228px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; height:11px; width:39px; left:251px; top:4192px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1 k M ði;</span></div>


<div class="txt" style="position:absolute; height:18px; width:19px; left:305px; top:4203px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ ¼ k Xn</span></div>



<div class="txt" style="position:absolute; left:361px; top:4228px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:388px; top:4185px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X </span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">m</span></div>
<div class="txt" style="position:absolute; left:391px; top:4228px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:419px; top:4203px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">M </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i;</span></div>
<div class="txt" style="position:absolute; left:460px; top:4203px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">:</span></div>
<div class="txt" style="position:absolute; left:530px; top:4174px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(1)</span></div>
<div class="txt" style="position:absolute; left:52px; top:4275px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Thus, the sum of gradient magnitudes in the original and</span></div>
<div class="txt" style="position:absolute; left:52px; top:4297px;"><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">@</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">uA</span><span id="f4" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">@</span><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">Iy</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">p</span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">0</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">n</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">ð</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">sg</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">i</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">a</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">;</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">lm</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">j</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">e</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">Þ</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">sp</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">%</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">lseh</span><span id="f4" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">@@</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">d</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">xI</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">o</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">ð</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ui</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">i</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ml</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">=</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">d</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">k</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">a</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">;</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ga</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">j</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">e</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">=</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ls</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">k</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">soh</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">Þ</span><span id="f6" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ob</span><span id="f4" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">@@</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ue</span><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">Iy</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">l</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">ð</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">d</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">i</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">m</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">=</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">b</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">k</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">oe</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">;</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">s</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">j</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">rt</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">=</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ley</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">k</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">la</span><span id="f3" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">Þ</span><span id="f1" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">.tpeTrdehsbeeyrrevafeobdroeu,stianacccfeaocr</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">@@</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">td</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">Ix</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">o</span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">0</span><span id="f1" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">ir</span><span id="f3" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">ð</span><span id="f1" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">n</span><span id="f2" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">i</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">og</span><span id="f2" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">; </span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">f</span><span id="f2" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">j</span><span id="f3" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">Þ</span><span id="f1" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">t</span><span id="f2" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">k</span><span id="f6" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f1" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">o.</span></div>
<div class="txt" style="position:absolute; height:251px; width:396px; left:52px; top:4367px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">the deﬁnition of gradient histograms, we expect the relationship between hq (computed over I) and hq0 (computed over I0) to be: h0q % khq. This allows us to approximate gradient histograms in an upsampled image using gradients computed at the original scale. <br><br>Experiments. One may verify experimentally that in images of natural scenes, upsampled using bilinear interpolation, the approximation hq0 % khq is reasonable. We use two sets of images for these experiments, one class speciﬁc and one class independent. First, we use the 1;237 cropped pedestrian images from the INRIA pedestrians training data set [21]. Each image is 128 Â 64 and contains a</span></div>











<div class="txt" style="position:absolute; height:481px; width:448px; left:578px; top:3897px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">pedestrian approximately </span><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">96 </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">pixels tall. The second image set contains 128 Â 64 windows cropped at random positions from the 1;218 images in the INRIA negative training set. We sample 5,000 windows but exclude nearly uniform windows, i.e., those with average gradient magnitude under 0:01, resulting in 4,280 images. We refer to the two sets as ‘pedestrian images’ and ‘natural images,’ although the latter is biased toward scenes that may (but do not) contain pedestrians. <br><br>In order to measure the ﬁdelity of this approximation, we deﬁne the ratio rq ¼ hq0 =hq and quantize orientation into Q ¼ 6 bins. Fig. 1a shows the distribution of rq for one bin on the 1;237 pedestrian and 4; 280 natural images given an upsampling of k ¼ 2 (results for other bins were similar). In both cases the mean is m % 2, as expected, and the variance is relatively small, meaning the approximation is unbiased and reasonable. <br><br>Thus, although individual gradients may change, gradient histograms in an upsampled and original image will be related by a multiplicative constant roughly equal to the scale change between them. We examine gradient histograms in downsampled images next.</span></div>





















<div class="txt" style="position:absolute; height:186px; width:390px; left:578px; top:4433px;"><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">3.2 Gradient Histograms in Downsampled Images While the information content of an upsampled image is roughly the same as that of the original image, information is typically lost during downsampling. However, we ﬁnd that the information loss is consistent and the resulting approximation takes on a similarly simple form. <br><br>If I contains little high frequency energy, then the approximation h0q % khq derived in Section 3.1 should apply. In general, however, downsampling results in loss of high</span></div>








<div style="position:absolute; left:0px; top:4680px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:4700px;" width="1129" height="1542" src="page4.png">
<div class="txt" style="position:absolute; left:52px; top:4748px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f5" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:4751px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1535</span></div>
<div class="txt" style="position:absolute; height:107px; width:975px; left:52px; top:5311px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 2. </span><span id="f11" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Approximating gradient histograms in images resampled by a factor of two. </span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">For each image set, we take the original image (green border) and generate an upsampled (blue) and downsampled (orange) version. At each scale we compute a gradient histogram with eight bins, multiplying each bin by 0:5 and 1=0:34 in the upsampled and downsampled histogram, respectively. Assuming the approximations from Section 3 hold, the three normalized gradient histograms should be roughly equal (the blue, green, and orange bars should have the same height at each orientation). For the ﬁrst four cases, the approximations are fairly accurate. In the last two cases, showing highly structured Brodatz textures with signiﬁcant high frequency content, the downsampling approximation fails. The ﬁrst four images are representative, the last two are carefully selected to demonstrate images with atypical statistics.</span></div>






<div class="txt" style="position:absolute; height:504px; width:435px; left:52px; top:5464px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">frequency content which can lead to measured gradients undershooting the extrapolated gradients. Let I0 now denote I downsampled by a factor of k. We expect that hq (computed over I) and h0q (computed over I0) will satisfy h0q hq=k. The question we seek to answer here is whether the information loss is consistent. <br><br>Experiments. As before, deﬁne rq ¼ h0q=hq. In Fig. 1b we show the distribution of rq for a single bin on the pedestrian and natural images given a downsampling factor of k ¼ 2. Observe that the information loss is consistent: rq is normally distributed around m % 0:34 &lt; 0:5 for natural images (and similarly m % 0:33 for pedestrians). This implies that hq0 % mhq could serve as a reasonable approximation for gradient histograms in images downsampled by k ¼ 2. <br><br>In other words, similarly to upsampling, gradient histograms computed over original and half resolution images tend to differ by a multiplicative constant (although the constant is not the inverse of the sampling factor). In Fig. 2 we show the quality of the above approximations on example images. The agreement between predictions and observations is accurate for typical images (but fails for images with atypical statistics).</span></div>






















<div class="txt" style="position:absolute; height:136px; width:422px; left:52px; top:6028px;"><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">3.3 Histograms of Normalized Gradients Suppose we replaced the gradient magnitude M by the normalized gradient magnitude Me deﬁned as Me ði; jÞ ¼ Mði; jÞ=ðMði; jÞ þ 0:005Þ, where M is the average gradient magnitude in each 11 Â 11 image patch (computed by convolving M with an L1 normalized 11 Â 11 triangle ﬁlter). Using the normalized gradient Me gives improved results in</span></div>






<div class="txt" style="position:absolute; height:343px; width:461px; left:578px; top:5464px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">the context of object detection (see Section 6). Observe that we have now introduced an additional nonlinearity to the gradient computation; do the previous results for gradient histograms still hold if we use Me instead of M? <br><br>In Fig. 1c we plot the distribution of rq ¼ hq0 =hq for histograms of normalized gradients given a downsampling factor of k ¼ 2. As with the original gradient histograms, the distributions of rq are normally distributed and have similar means for pedestrian and natural images (m % 0:26 and m % 0:27, respectively). Observe, however, that the expected value of rq for normalized gradient histograms is quite different than for the original histograms (Fig. 1b). <br><br>Deriving analytical expressions governing the scaling properties of progressively more complex feature types would be difﬁcult or even impossible. Instead, in Section 4 we describe a general law governing feature scaling.</span></div>















<div class="txt" style="position:absolute; left:578px; top:5859px;"><span id="f7" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">4 S</span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">TATISTICS OF </span><span id="f7" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">M</span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ULTISCALE </span><span id="f7" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">F</span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">EATURES</span></div>
<div class="txt" style="position:absolute; height:274px; width:429px; left:578px; top:5894px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">To understand more generally how features behave in resampled images, we turn to the study of natural image statistics [7], [33]. The analysis below provides a deep understanding of the behavior of multiscale features. The practical result is a simple yet powerful approach for predicting the behavior of gradients and other lowlevel features in resampled images without resorting to analytical derivations that may be difﬁcult except under the simplest conditions. <br><br>We begin by deﬁning a broad family of features. Let V be any lowlevel shift invariant function that takes an image I and creates a new channel image C ¼ VðIÞ where a channel C is a perpixel feature map such that output pixels in C are</span></div>












<div style="position:absolute; left:0px; top:6230px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:6250px;" width="1129" height="1542" src="page5.png">
<div class="txt" style="position:absolute; left:52px; top:6301px;"><span id="f11" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1536</span></div>
<div class="txt" style="position:absolute; left:334px; top:6301px;"><span id="f11" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; height:318px; width:435px; left:52px; top:6343px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">computed from corresponding patches of input pixels in </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I (thus preserving overall image layout). C may be downsampled relative to I and may contain multiple layers k. We deﬁne a feature fVPðIÞ as a weighted sum of the channel C ¼ VðIÞ: fVðIÞ ¼ ijk wijkCði; j; kÞ. Numerous local and global features can be written in this form including gradient histograms, linear ﬁlters, color statistics, and others [29]. Any such lowlevel shift invariant V can be used, making this representation quite general. <br><br>Let Is denote I at scale s, where the dimensions hs Â ws of Is are s times the dimensions of I. For s &lt; 1, Is (which denotes a higher resolution version of I) typically differs from I upsampled by s, while for s &lt; 1 an excellent approximation of Is can be obtained by downsampling I. Next, for simplicity we redeﬁne fVðIsÞ as1</span></div>














<div class="txt" style="position:absolute; left:201px; top:6697px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span><span id="f5" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">X</span></div>
<div class="txt" style="position:absolute; left:106px; top:6715px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ  </span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">h</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">w</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">k </span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">ijk </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i; j; k</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">where </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">:</span></div>
<div class="txt" style="position:absolute; left:530px; top:6716px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(2)</span></div>
<div class="txt" style="position:absolute; height:114px; width:422px; left:52px; top:6773px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">In other words </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">denotes the </span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">global mean </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">of </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">computed over locations ij and layers k. Everything in the following derivations based on global means also holds for local means (e.g., local histograms). <br><br>Our goal is to understand how fVðIsÞ behaves as a function of s for any choice of shift invariant V.</span></div>





<div class="txt" style="position:absolute; height:297px; width:455px; left:52px; top:6943px;"><span id="f8" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">4.1 Power Law Governs Feature Scaling Ruderman and Bialek [33], [67] explored how the statistics of natural images behave as a function of the scale at which an image ensemble was captured, i.e., the visual angle corresponding to a single pixel. Let fðIÞ denote an arbitrary (scalar) image statistic and E½Á denote expectation over an ensemble of natural images. Ruderman and Bialek made the fundamental discovery that the ratio of E½fðIs1 Þ to E½fðIs2 Þ, computed over two ensembles of natural images captured at scales s1 and s2, respectively, depends only on the ratio of s1=s2 and is independent of the absolute scales s1 and s2 of the ensembles. <br><br>Ruderman and Bialek’s ﬁndings imply that E½fðIsÞ follows a power law2:</span></div>













<div class="txt" style="position:absolute; left:169px; top:7282px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">E</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">½</span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">1 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">=E</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">½</span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">2 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ ¼ ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">=s</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">2</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f9" style="font-size:9px;vertical-align:super;color:rgba(34,30,31,1);">f </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">:</span></div>
<div class="txt" style="position:absolute; left:530px; top:7288px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(3)</span></div>
<div class="txt" style="position:absolute; height:115px; width:403px; left:52px; top:7337px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Every statistic </span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">f </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">will have its own corresponding </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f9" style="font-size:10px;vertical-align:sub;color:rgba(34,30,31,1);">f</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">. In the context of our work, for any channel type V we can use the scalar fVðIÞ in place of fðIÞ and V in place of f. While Eq. (3) gives the behavior of fV w.r.t. to scale over an ensemble of images, we are interested in the behavior of fV for a single image.</span></div>





<div class="txt" style="position:absolute; height:216px; width:492px; left:76px; top:7505px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">1. The deﬁnition of </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f3" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ </span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">in Eq. (2) differs from our previous deﬁnition in [39], where fðI; sÞ denoted the channel sum after resampling by 2s. The new deﬁnition and notation allow for a cleaner derivation, and the exponential scaling law becomes a more intuitive power law. 2. Let F ðsÞ ¼ E½fðIsÞ. We can rewrite the observation by saying there exists a function R such that F ðs1Þ=F ðs2Þ ¼ Rðs1=s2Þ. Applying repeatedly gives F ðs1Þ=F ð1Þ ¼ Rðs1Þ, F ð1Þ=F ðs2Þ ¼ Rð1=s2Þ, and F ðs1Þ=F ðs2Þ ¼ Rðs1=s2Þ. Therefore Rðs1=s2Þ ¼ Rðs1ÞRð1=s2Þ. Next, let R0ðsÞ ¼ RðesÞ and observe that R0ðs1 þ s2Þ ¼ R0ðs1ÞR0ðs2Þ since Rðs1s2Þ ¼ Rðs1ÞRðs2Þ. If R0 is also continuous and nonzero, then it must take the form R0ðsÞ ¼ eÀs for some constant  [68]. This implies RðsÞ ¼ R0ðlnðsÞÞ ¼ eÀ lnðsÞ ¼ sÀ. Therefore, E½fðIsÞ must follow a power law (see also Eq. (9) in [67]).</span></div>












<div class="txt" style="position:absolute; height:321px; width:500px; left:602px; top:6344px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">We observe that a single image can itself be considered an ensemble of image patches (smaller images). Since V is shift invariant, we can interpret fVðIÞ as computing the average of fVðIkÞ over every patch Ik of I and therefore Eq. (3) can be applied directly for a single image. We formalize this below. <br><br>We can decompose an image I into K smaller images I1 . . . IK such that I ¼ ½I1 Á Á Á IK. Given that V must be shift invariant and ignoring boundary effects gives VðIÞ ¼ Vð½I1 Á Á Á IKÞ % ½VðI1Þ Á Á Á VðIKÞ, and substituting into Eq. (2) yields fVðIÞ % SfVðIkÞ=K. However, we can consider I1 Á Á Á IK as a (small) image ensemble, and fVðIÞ % E½fVðIkÞ an expectation over that ensemble. Therefore, substituting fVðIs1 Þ % E½fVðIsk1 Þ and fVðIs2 Þ % E½fVðIsk2 Þ into Eq. (3) yields:</span></div>














<div class="txt" style="position:absolute; left:692px; top:6706px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">1 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">=f</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">2 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ ¼ ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">=s</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">2</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f3" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">V </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">þ E </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">;</span></div>
<div class="txt" style="position:absolute; left:1056px; top:6712px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(4)</span></div>
<div class="txt" style="position:absolute; height:183px; width:422px; left:578px; top:6751px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">where we use </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">E </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">to denote the deviation from the power law for a given image. Each channel type V has its own corresponding V, which we can determine empirically. <br><br>In Section 4.2 we show that on average Eq. (4) provides a remarkably good ﬁt for multiple channel types and image sets (i.e., we can ﬁt V such that E½E % 0). Additionally, experiments in Section 4.3 indicate that the magnitude of deviation for individual images, E½E2, is reasonable and increases only gradually as a function of s1=s2.</span></div>








<div class="txt" style="position:absolute; height:71px; width:364px; left:578px; top:6981px;"><span id="f8" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">4.2 Estimating </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);"> We perform a series of experiments to verify Eq. (4) and estimate V for numerous channel types V. To estimate V for a given V, we ﬁrst compute:</span></div>



<div class="txt" style="position:absolute; left:721px; top:7111px;"><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">m</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span></div>
<div class="txt" style="position:absolute; height:18px; width:19px; left:746px; top:7111px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ 1 N X N</span></div>



<div class="txt" style="position:absolute; left:789px; top:7135px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i</span><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f6" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span></div>
<div class="txt" style="position:absolute; left:816px; top:7095px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f5" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">si</span><span id="f5" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">Á</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">=f</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f5" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">i </span><span id="f5" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">Á</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">;</span></div>
<div class="txt" style="position:absolute; left:1056px; top:7112px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(5)</span></div>
<div class="txt" style="position:absolute; height:469px; width:487px; left:578px; top:7163px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">for </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">N </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">images </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">i </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">and multiple values of </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s &lt; </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, where </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">si </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">is obtained by downsampling I1i ¼ Ii. We use two image ensembles, one of N ¼ 1; 237 pedestrian images and one of N ¼ 4; 280 natural images (for details see Section 3.1). According to Eq. (4), ms ¼ sÀV þ E½E. Our goal is to ﬁt V accordingly and verify the ﬁdelity of Eq. (4) for various channel types V (i.e., verify that E½E % 0). <br><br>For each V, we measure ms according to Eq. (5) across three octaves with eight scales per octave for a total of 24 measurements at s ¼ 2À81; . . . ; 2À284. Since image dimensions are rpouﬃﬃndeﬃﬃdtﬃﬃoﬃ the nearest integer, we compute and use s0 ¼ hsws=hw, where h Â w and hs Â ws are the dimensions of the original and downsampled images, respectively. <br><br>In Fig. 3 we plot ms versus s0 using a loglog plot for six channel types for both the pedestrian and natural images.3 In all cases ms follows a power law with all measurements falling along a line on the loglog plots, as predicted. However, close inspection shows ms does not start exactly at 1 as expected: downsampling introduces a minor amount of blur even for small downsampling factors. We thus expect</span></div>



















<div class="txt" style="position:absolute; height:35px; width:455px; left:602px; top:7685px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">3. Fig. 3 generalizes the results shown in Fig. 1. However, by switching from channel sums to channel means, m1=2 in Figs. 3a and 3b is 4Â larger than m in Figs. 1b and 1c, respectively.</span></div>


<div style="position:absolute; left:0px; top:7780px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:7800px;" width="1129" height="1542" src="page6.png">
<div class="txt" style="position:absolute; left:52px; top:7848px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f6" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:7851px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1537</span></div>
<div class="txt" style="position:absolute; height:0px; width:32px; left:52px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 3. Power</span></div>


<div class="txt" style="position:absolute; height:0px; width:45px; left:149px; top:8286px;"><span id="f11" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">law feature</span></div>

<div class="txt" style="position:absolute; left:230px; top:8286px;"><span id="f11" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">scaling</span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">.</span></div>
<div class="txt" style="position:absolute; height:0px; width:26px; left:288px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">For each</span></div>

<div class="txt" style="position:absolute; height:0px; width:45px; left:355px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">of six channel</span></div>


<div class="txt" style="position:absolute; left:455px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">types</span></div>
<div class="txt" style="position:absolute; height:0px; width:23px; left:497px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">we plot</span></div>

<div class="txt" style="position:absolute; left:551px; top:8286px;"><span id="f1" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">m</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span></div>
<div class="txt" style="position:absolute; left:573px; top:8286px;"><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span></div>
<div class="txt" style="position:absolute; height:11px; width:45px; left:591px; top:8284px;"><span id="f6" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">1 N</span></div>

<div class="txt" style="position:absolute; left:602px; top:8274px;"><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">P </span><span id="f2" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">f</span><span id="f5" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">si</span><span id="f4" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">=f</span><span id="f5" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">I</span><span id="f6" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">i </span><span id="f4" style="font-size:14px;vertical-align:sub;color:rgba(34,30,31,1);">Þ</span></div>
<div class="txt" style="position:absolute; height:0px; width:45px; left:719px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">for s % 2À18 ; .. .; 2À284 on a loglog</span></div>









<div class="txt" style="position:absolute; height:0px; width:26px; left:944px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">plot for both</span></div>


<div class="txt" style="position:absolute; left:1032px; top:8286px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">pedes-</span></div>
<div class="txt" style="position:absolute; height:126px; width:1097px; left:52px; top:8307px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">trian and natural image ensembles. Plots of </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f5" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:9px;vertical-align:sub;color:rgba(34,30,31,1);">1 </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">=f</span><span id="f5" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f6" style="font-size:9px;vertical-align:sub;color:rgba(34,30,31,1);">2 </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ </span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">for 20 randomly selected pedestrian images are shown as faint gray lines. Additionally the bestﬁt line to ms for the natural images is shown. The resulting  and expected error jE½Ej are given in the plot legends. In all cases the ms follow a power law as predicted by Eq. (4) and are nearly identical for both pedestrian and natural images, showing the estimate of  is robust and generally applicable. The tested channels are: (a) histograms of gradients described in Section 3; (b) histograms of normalized gradients described in Section 3.3; (c) a difference of gaussian (DoG) ﬁlter (with inner and outer s of 0:7p1 and1:14ﬃﬃ,resﬃﬃpﬃﬃ ectively); (d) grayscale images (with  ¼ 0 as expected); (e) pixel standard deviation computed over local 5 Â 5 neighborhoods Cði;jÞ¼ E½Iði;jÞ2ÀE½Iði;jÞ; (f) HOG [21] with 4 Â 4 spatial bins (results were averaged over HOG’s 36 channels). Code for generating such plots is available (see chnsScaling.m in Piotr’s Toolbox).</span></div>






<div class="txt" style="position:absolute; height:118px; width:416px; left:52px; top:8481px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">m</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">to have the form </span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">m</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">a</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">V </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, with </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">a</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">6¼ </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1 </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">as an artifact of the interpolation. Note that aV is only necessary for estimating V from downsampled images and is not used subsequently. To estimate aV and V, we use a least squares ﬁt of log2 puted</span></div>





<div class="txt" style="position:absolute; height:24px; width:52px; left:106px; top:8575px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">m</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">0 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ over</span></div>

<div class="txt" style="position:absolute; height:26px; width:136px; left:150px; top:8573px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">a</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">0 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">À </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">log</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">2</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">0 natural images</span></div>

<div class="txt" style="position:absolute; height:24px; width:78px; left:293px; top:8575px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">to the </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">24 (and set</span></div>

<div class="txt" style="position:absolute; height:15px; width:149px; left:384px; top:8576px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">measurements comaV ¼ 2aV0 ). Resulting</span></div>

<div class="txt" style="position:absolute; height:345px; width:422px; left:52px; top:8621px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">estimates of </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">are given in plot legends in Fig. 3. <br><br>There is strong agreement between the resulting bestﬁt lines and the observations. In legend brackets in Fig. 3 we report expected error jE½Ej ¼ jms À aVsÀV j for both natural and pedestrian images averaged over s (using aV and V estimated using natural images). For basic gradient histograms jE½Ej ¼ 0:018 for natural images and jE½Ej ¼ 0:037 for pedestrian images. Indeed, for every channel type Eq. (4) is an excellent ﬁt to the observations ms for both image ensembles. <br><br>The derivation of Eq. (4) depends on the distribution of image statistics being stationary with respect to scale; that this holds for all channel types tested, and with nearly an identical constant for both pedestrian and natural images, shows the estimate of V is robust and generally applicable.</span></div>















<div class="txt" style="position:absolute; left:678px; top:8488px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">stdev</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">½</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">si</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">=f</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f6" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">i </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ ¼ </span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">stdev</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">½E</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">;</span></div>
<div class="txt" style="position:absolute; left:1056px; top:8493px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(6)</span></div>
<div class="txt" style="position:absolute; height:137px; width:494px; left:578px; top:8531px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">where ‘stdev’ denotes the sample standard deviation (computed over N images) and E is the error associated with each image and scaling factor as deﬁned in Eq. (4). In Section 4.2 we conﬁrmed that Ep½Eﬃﬃ%ﬃﬃﬃ 0, our goal now is to understand how ss ¼ stdev½E % E½E2 behaves. <br><br>In Fig. 4 we plot ss as a function of s for the same channels</span></div>






<div class="txt" style="position:absolute; height:0px; width:116px; left:616px; top:8668px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">as in Fig.</span></div>


<div class="txt" style="position:absolute; height:0px; width:39px; left:696px; top:8668px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">3. In legend</span></div>


<div class="txt" style="position:absolute; left:799px; top:8668px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">brackets</span></div>
<div class="txt" style="position:absolute; height:0px; width:39px; left:873px; top:8668px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">we report</span></div>

<div class="txt" style="position:absolute; left:959px; top:8667px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span></div>
<div class="txt" style="position:absolute; height:1px; width:19px; left:982px; top:8668px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">for s ¼</span></div>


<div class="txt" style="position:absolute; height:14px; width:6px; left:1045px; top:8665px;"><span id="f6" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 2</span></div>

<div class="txt" style="position:absolute; left:1056px; top:8668px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">for</span></div>
<div class="txt" style="position:absolute; height:298px; width:422px; left:578px; top:8691px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">both natural and pedestrian images; for all channels studied s1=2 &lt; :2. In all cases ss increases gradually with increasing s and the deviation is low for small s. The expected magnitude of E varies across channels, for example histograms of normalized gradients (Fig. 4b) have lower ss than their unnormalized counterparts (Fig. 4a). The trivial grayscale channel (Fig. 4d) has ss ¼ 0 as the approximation is exact. <br><br>Observe that often ss is greater for natural images than for pedestrian images. Many of the natural images contain relatively little structure (e.g., a patch of sky), for such images fVðIÞ is small for certain V (e.g., simple gradient histograms) resulting in more variance in the ratio in Eq. (4). For HOG channels (Fig. 4f), which have additional normalization, this effect is minimized.</span></div>













<div class="txt" style="position:absolute; height:235px; width:461px; left:52px; top:9033px;"><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">4.3 Deviation for Individual Images In Section 4.2 we veriﬁed that Eq. (4) holds for an ensemble of images; we now examine the magnitude of deviation from the power law for individual images. We study the effect this has in the context of object detection in Section 6. <br><br>Plots of fVðIs1 Þ=fVðIs2 Þ for randomly selected images are shown as faint gray lines in Fig. 3. The individual curves are relatively smooth and diverge only somewhat from the bestﬁt line. We quantify their deviation by deﬁning ss analogously to ms in Eq. (5):</span></div>










<div class="txt" style="position:absolute; height:231px; width:422px; left:578px; top:9037px;"><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">4.4 Miscellanea We conclude this section with additional observations. <br><br>Interpolation method. Varying the interpolation algorithm for image resampling does not have a major effect. In Fig. 5a, we plot m1=2 and s1=2 for normalized gradient histograms computed using nearest neighbor, bilinear, and bicubic interpolation. In all three cases both m1=2 and s1=2 remain essentially unchanged. <br><br>Window size. All preceding experiments were performed on 128 Â 64 windows. In Fig. 5b we plot the effect of varying the window size. While m1=2 remains relatively constant,</span></div>










<div style="position:absolute; left:0px; top:9330px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:9350px;" width="1129" height="1542" src="page7.png">
<div class="txt" style="position:absolute; left:52px; top:9401px;"><span id="f9" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1538</span></div>
<div class="txt" style="position:absolute; left:334px; top:9401px;"><span id="f9" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; left:970px; top:9804px;"><span id="f11" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ</span></div>
<div class="txt" style="position:absolute; height:56px; width:994px; left:52px; top:9821px;"><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 4. </span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Power law deviation for individual images</span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">. For each of the six channel types described in Fig. 3 we plot </span><span id="f1" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f3" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">versus </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">s </span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">where </span><span id="f1" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f3" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">E</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">½E</span><span id="f2" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">2</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"> </span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">and </span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">E </span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">is the deviation from the power law for a single image as deﬁned in Eq. (4). In brackets we report s1=2 for both natural and pedestrian images. ss increases gradually as a function of s, meaning that not only does Eq. (4) hold for an ensemble of images but also the deviation from the power law for individual images is low for small s.</span></div>



<div class="txt" style="position:absolute; left:52px; top:9922px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">1</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">=</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">2 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">increases with decreasing window size (see also the</span></div>
<div class="txt" style="position:absolute; height:527px; width:455px; left:52px; top:9946px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">derivation of Eq. (4)). <br><br>Upsampling. The power law can predict features in higher resolution images but not upsampled images. In practice, though, we want to predict features in higher resolution as opposed to (smooth) upsampled images. <br><br>Robust estimation. In preceding derivations, when computing fVðIs1 Þ=fVðIs2 Þ we assumed that fVðIs2 Þ 6¼ 0. For the V’s considered this was the case after windows of near uniform intensity were excluded (see Section 3.1). Alternatively, we have found that excluding I with fVðIÞ % 0 when estimating  results in more robust estimates. <br><br>Sparse channels. For sparse channels where frequently fVðIÞ % 0, e.g., the output of a slidingwindow object detector, s will be large. Such channels may not be good candidates for the power law approximation. <br><br>Oneshot estimates. We can estimate  as described in Section 4.2 using a single image in place of an ensemble (N ¼ 1). Such estimates are noisy but not entirely unreasonable; e.g., on normalized gradient histograms (with  % 0:101) the mean of 4,280 single image estimates of  if 0:096 and the standard deviation of the estimates is 0:073. <br><br>Scale range. We expect the power law to break down at extreme scales not typically encountered under natural viewing conditions (e.g., under high magniﬁcation).</span></div>























<div class="txt" style="position:absolute; left:578px; top:9921px;"><span id="f8" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">5 F</span><span id="f8" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">AST </span><span id="f8" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">F</span><span id="f8" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">EATURE </span><span id="f8" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">P</span><span id="f8" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">YRAMIDS</span></div>
<div class="txt" style="position:absolute; height:91px; width:403px; left:578px; top:9956px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">We introduce a novel, efﬁcient scheme for computing feature pyramids. First, in Section 5.1 we outline an approach for scaling feature channels. Next, in Section 5.2 we show its application to constructing feature pyramids efﬁciently and we analyze computational complexity in Section 5.3.</span></div>




<div class="txt" style="position:absolute; height:210px; width:422px; left:578px; top:10105px;"><span id="f8" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">5.1 Feature Channel Scaling We propose an extension of the power law governing feature scaling introduced in Section 4 that applies directly to channel images. As before, let Is denote I captured at scale s and RðI; sÞ denote I resampled by s. Suppose we have computed C ¼ VðIÞ; can we predict the channel image Cs ¼ VðIsÞ at a new scale s using only C? <br><br>The standard approach is to compute Cs ¼ VðRðI; sÞÞ, ignoring the information contained in C ¼ VðIÞ. Instead, we propose the following approximation:</span></div>









<div class="txt" style="position:absolute; left:749px; top:10355px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">% </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">R</span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C; s</span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ Á </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f7" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f3" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f6" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">V </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">:</span></div>
<div class="txt" style="position:absolute; left:1056px; top:10360px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(7)</span></div>
<div class="txt" style="position:absolute; left:578px; top:10400px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">A visual demonstration of Eq. (7) is shown in Fig. 6.</span></div>
<div class="txt" style="position:absolute; height:89px; width:487px; left:52px; top:10731px;"><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 5. </span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Effect of the interpolation algorithm and window size on channel scaling. We plot m1=2 (bar height) and s1=2 (error bars) for normalized gradient histograms (see Section 3.3) . (a) Varying the interpolation algorithm for resampling does not have a major effect on either m1=2 or s1=2. (b) Decreasing window size leaves m1=2 relatively unchanged but results in increasing s1=2.</span></div>





<div class="txt" style="position:absolute; height:108px; width:474px; left:578px; top:10713px;"><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 6. </span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Feature channel scaling</span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">. Suppose we have computed </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">C </span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f6" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">V</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f9" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">; can we predict Cs ¼ VðIsÞ at a new scale s? Top. the standard approach is to compute Cs ¼ VðRðI; sÞÞ, ignoring the information contained in C ¼ VðIÞ. Bottom. instead, based on the power law introduced in Section 4, we propose to approximate Cs by RðC; sÞ Á sÀV . This approach is simple, general, and accurate, and allows for fast feature pyramid construction.</span></div>






<div style="position:absolute; left:0px; top:10880px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:10900px;" width="1129" height="1542" src="page8.png">
<div class="txt" style="position:absolute; left:52px; top:10948px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f3" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:10951px;"><span id="f10" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1539</span></div>
<div class="txt" style="position:absolute; height:93px; width:435px; left:76px; top:10993px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Eq. (7) follows from Eq. (4). Setting </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">1 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f3" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">2 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, and rearranging Eq. (4) gives fVðIsÞ % fVðIÞsÀV . This relation must hold not only for the original images but also for any pair of corresponding windows ws and w in Is and I, respectively. Expanding yields:</span></div>




<div class="txt" style="position:absolute; left:218px; top:11116px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f6" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">sw</span><span id="f2" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">s </span><span id="f6" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">Á </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">% </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f5" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">w</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">V</span></div>
<div class="txt" style="position:absolute; height:25px; width:26px; left:160px; top:11159px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1 jwsj</span></div>

<div class="txt" style="position:absolute; left:188px; top:11153px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X</span></div>
<div class="txt" style="position:absolute; left:183px; top:11196px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i;j</span><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">2</span><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">w</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span></div>
<div class="txt" style="position:absolute; left:224px; top:11171px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i;</span></div>
<div class="txt" style="position:absolute; height:18px; width:19px; left:267px; top:11171px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ % 1 jwj X</span></div>




<div class="txt" style="position:absolute; left:333px; top:11196px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">i;j</span><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">2</span><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">w</span></div>
<div class="txt" style="position:absolute; left:368px; top:11171px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">i;</span></div>
<div class="txt" style="position:absolute; left:405px; top:11168px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">j</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">V</span></div>
<div class="txt" style="position:absolute; left:261px; top:11217px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">% </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">R</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C; s</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">À</span><span id="f2" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:11px;vertical-align:super;color:rgba(34,30,31,1);">V </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">:</span></div>
<div class="txt" style="position:absolute; height:23px; width:65px; left:52px; top:11278px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">The ﬁnal windows</span></div>

<div class="txt" style="position:absolute; left:135px; top:11278px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">P</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">li</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">w</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">n</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">e</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">C</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">f</span><span id="f4" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">0</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">=</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">o</span><span id="f4" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">j</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">l</span><span id="f2" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">w</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">lo</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">w</span><span id="f4" style="font-size:15px;vertical-align:sub;color:rgba(34,30,31,1);">j %</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">s</span></div>
<div class="txt" style="position:absolute; left:258px; top:11278px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">P</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">because if for</span></div>
<div class="txt" style="position:absolute; left:278px; top:11300px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">w </span><span id="f2" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">C=</span><span id="f4" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">j</span><span id="f2" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">w</span><span id="f4" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">j</span><span id="f1" style="font-size:15px;vertical-align:super;color:rgba(34,30,31,1);">, then</span></div>
<div class="txt" style="position:absolute; height:19px; width:26px; left:399px; top:11278px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">all C0 %</span></div>

<div class="txt" style="position:absolute; height:22px; width:84px; left:432px; top:11278px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">corresponding RðC; sÞ.</span></div>

<div class="txt" style="position:absolute; height:298px; width:416px; left:76px; top:11323px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">On a </span><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">perpixel basis</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, the approximation of </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">in Eq. (7) may be quite noisy. The standard deviation ss of the ratio fVðIsws Þ=fVðIwÞ depends on the size of the window w: ss increases as w decreases (see Fig. 5b). Therefore, the accuracy of the approximation for Cs will improve if information is aggregated over multiple pixels of Cs. <br><br>A simple strategy for aggregating over multiple pixels and thus improving robustness is to downsample and/or smooth Cs relative to Is (each pixel in the resulting channel will be a weighted sum of pixels in the original full resolution channel). Downsampling Cs also allows for faster pyramid construction (we return to this in Section 5.2). For object detection, we typically downsample channels by 4Â to 8Â (e.g., HOG [21] uses 8 Â 8 bins).</span></div>













<div class="txt" style="position:absolute; height:125px; width:500px; left:578px; top:11293px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 7. </span><span id="f11" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fast feature pyramids</span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">. Color and grayscale icons represent images and channels; horizontal and vertical arrows denote computation of R and V. Top. The standard pipeline for constructing a feature pyramid requires computing Is ¼ RðI; sÞ followed by Cs ¼ VðIsÞ for every s. This is costly. Bottom. We propose computing Is ¼ RðI; sÞ and Cs ¼ VðIsÞ for only a sparse set of s (once per octave). Then, at intermediate Cs %</span></div>







<div class="txt" style="position:absolute; height:15px; width:136px; left:623px; top:11400px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">scales </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s </span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">is RðCs0 ; s=s0Þðs=s0</span></div>

<div class="txt" style="position:absolute; height:13px; width:117px; left:728px; top:11400px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">computed using ÞÀV where s0 is</span></div>

<div class="txt" style="position:absolute; height:18px; width:195px; left:856px; top:11400px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">the approximation in Eq. (7): the nearest scale for which we</span></div>

<div class="txt" style="position:absolute; height:37px; width:474px; left:578px; top:11435px;"><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">have </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:9px;vertical-align:baseline;color:rgba(34,30,31,1);">0 </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:11px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:9px;vertical-align:baseline;color:rgba(34,30,31,1);">0 </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f10" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">. In the proposed scheme, the number of computations of R is constant while (more expensive) computations of V are reduced considerably.</span></div>


<div class="txt" style="position:absolute; height:117px; width:396px; left:578px; top:11513px;"><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">5.3 Complexity Analysis The computational savings of computing approximate feature pyramids is signiﬁcant. Assume the cost of computing V is linear in the number of pixels in an n Â n image (as is often the case). The cost of constructing a feature pyramid with m scales per octave is</span></div>





<div class="txt" style="position:absolute; height:302px; width:409px; left:52px; top:11678px;"><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">5.2 Fast Feature Pyramids A feature pyramid is a multiscale representation of an image I where channels Cs ¼ VðIsÞ are computed at every scale s. Scales are sampled evenly in logspace, starting at s ¼ 1, with typically four to 12 scales per octave (an octave is the interval between one scale and another with half or double its value). The standard approach to constructing a feature pyramid is to compute Cs ¼ VðRðI; sÞÞ for every s, see Fig. 7 (top). <br><br>The approximation in Eq. (7) suggests a straightforward method for efﬁcient feature pyramid construction. We begin by computing Cs ¼ VðRðI; sÞÞ at just one scale per octave computed</span></div>













<div class="txt" style="position:absolute; height:24px; width:52px; left:151px; top:11956px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">s </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">2 f</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">; using</span></div>

<div class="txt" style="position:absolute; height:13px; width:6px; left:217px; top:11954px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 2</span></div>

<div class="txt" style="position:absolute; left:226px; top:11956px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">;</span></div>
<div class="txt" style="position:absolute; height:13px; width:6px; left:235px; top:11954px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 4</span></div>

<div class="txt" style="position:absolute; height:5px; width:188px; left:221px; top:11979px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s ; . . .g). At intermediate % RðCs0 ; s=s0Þðs=s0ÞÀV</span></div>


<div class="txt" style="position:absolute; height:23px; width:45px; left:449px; top:11957px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">scales, where</span></div>

<div class="txt" style="position:absolute; height:23px; width:2px; left:512px; top:11956px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s s0 is 2</span></div>



<div class="txt" style="position:absolute; left:52px; top:12002px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">f</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">1</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">;</span></div>
<div class="txt" style="position:absolute; height:13px; width:6px; left:79px; top:12000px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 2</span></div>

<div class="txt" style="position:absolute; left:89px; top:12002px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">;</span></div>
<div class="txt" style="position:absolute; height:13px; width:6px; left:97px; top:12000px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1 4</span></div>

<div class="txt" style="position:absolute; height:1px; width:19px; left:107px; top:12002px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">; . . .g is the</span></div>





<div class="txt" style="position:absolute; left:232px; top:12003px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">nearest</span></div>
<div class="txt" style="position:absolute; left:309px; top:12003px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">scale</span></div>
<div class="txt" style="position:absolute; left:366px; top:12003px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">for</span></div>
<div class="txt" style="position:absolute; left:405px; top:12003px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">which</span></div>
<div class="txt" style="position:absolute; left:473px; top:12003px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">we</span></div>
<div class="txt" style="position:absolute; left:513px; top:12003px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">have</span></div>
<div class="txt" style="position:absolute; height:345px; width:403px; left:52px; top:12024px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">0 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">V</span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f2" style="font-size:12px;vertical-align:sub;color:rgba(34,30,31,1);">s</span><span id="f4" style="font-size:11px;vertical-align:baseline;color:rgba(34,30,31,1);">0 </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, see Fig. 7 (bottom). <br><br>Computing Cs ¼ VðRðI; sÞÞ at one scale per octave provides a good tradeoff between speed and accuracy. The cost of evaluating V is within 33 percent of computing VðIÞ at the original scale (see Section 5.3) and channels do not need to be approximated beyond half an octave (keeping error low, see Section 4.3). While the number of evaluations of R is constant (evaluations of RðI; sÞ are replaced by RðC; sÞ), if each Cs is downsampled relative to Is as described in Section 5.1, evaluating RðC; sÞ is faster than RðI; sÞ. <br><br>Alternate schemes, such as interpolating between two nearby scales s0 for each intermediate scale s or evaluating V more densely, could result in even higher pyramid accuracy (at increased cost). However, the proposed approach proves sufﬁcient for object detection (see Section 6).</span></div>















<div class="txt" style="position:absolute; height:14px; width:58px; left:611px; top:11667px;"><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">X </span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">1 n22À2k=m</span></div>

<div class="txt" style="position:absolute; left:613px; top:11710px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">k</span><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">0</span></div>
<div class="txt" style="position:absolute; height:5px; width:71px; left:718px; top:11685px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ n2 X 1 ð4À1=mÞk</span></div>



<div class="txt" style="position:absolute; left:761px; top:11710px;"><span id="f2" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">k</span><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">¼</span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">0</span></div>
<div class="txt" style="position:absolute; height:12px; width:58px; left:860px; top:11685px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ 1 n2 À 4À1=m</span></div>



<div class="txt" style="position:absolute; height:0px; width:19px; left:963px; top:11685px;"><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">% mn2 ln4 :</span></div>



<div class="txt" style="position:absolute; left:1056px; top:11686px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">(8)</span></div>
<div class="txt" style="position:absolute; height:91px; width:396px; left:578px; top:11741px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">The second equality follows from the formula for a sum of a geometric series; the last approximation is valid for large m (and follows from l’Ho^pital’s rule). In the proposed approach we compute V once per octave (m ¼ 1). The total cost</span></div>




<div class="txt" style="position:absolute; left:618px; top:11832px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">is</span></div>
<div class="txt" style="position:absolute; height:14px; width:94px; left:638px; top:11829px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">4 3</span></div>

<div class="txt" style="position:absolute; height:3px; width:32px; left:648px; top:11829px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">n</span><span id="f3" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);">2</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, which</span></div>

<div class="txt" style="position:absolute; height:0px; width:26px; left:737px; top:11832px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">is only</span></div>

<div class="txt" style="position:absolute; height:0px; width:45px; left:801px; top:11832px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">33 percent</span></div>

<div class="txt" style="position:absolute; left:896px; top:11832px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">more</span></div>
<div class="txt" style="position:absolute; left:946px; top:11832px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">than</span></div>
<div class="txt" style="position:absolute; height:0px; width:26px; left:991px; top:11832px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">the cost</span></div>

<div class="txt" style="position:absolute; left:1064px; top:11832px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">of</span></div>
<div class="txt" style="position:absolute; height:92px; width:396px; left:578px; top:11855px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">computing single scale features. Typical detectors are evaluated on eight to 12 scales per octave [31], thus according to (8) we achieve an order of magnitude savings over computing V densely (and intermediate Cs are computed efﬁciently through resampling afterward).</span></div>




<div class="txt" style="position:absolute; left:578px; top:12002px;"><span id="f9" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">6 A</span><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">PPLICATIONS TO </span><span id="f9" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">O</span><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">BJECT </span><span id="f9" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">D</span><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ETECTION</span></div>
<div class="txt" style="position:absolute; height:229px; width:396px; left:578px; top:12037px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">We demonstrate the effectiveness of fast feature pyramids in the context of object detection with three distinct detection frameworks. First, in Section 6.1 we show the efﬁcacy of our approach with a simple yet stateoftheart pedestrian detector we introduce in this work called Aggregated Channel Features (ACF). In Section 6.2 we describe an alternate approach for exploiting approximate multiscale features using integral images computed over the same channels (integral channel features or ICF), much as in our previous work [29], [39]. Finally, in Section 6.3 we approximate HOG feature pyramids for use with deformable part models [35].</span></div>










<div class="txt" style="position:absolute; height:48px; width:370px; left:578px; top:12320px;"><span id="f9" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">6.1 Aggregated Channel Features The ACF detection framework is conceptually straightforward (Fig. 8). Given an input image I, we compute several</span></div>


<div style="position:absolute; left:0px; top:12430px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:12450px;" width="1129" height="1542" src="page9.png">
<div class="txt" style="position:absolute; left:52px; top:12501px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1540</span></div>
<div class="txt" style="position:absolute; left:334px; top:12501px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; height:54px; width:962px; left:52px; top:12703px;"><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 8. Overview of the ACF detector. Given an input image </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, we compute several channels </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">C </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">V</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, sum every block of pixels in </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, and smooth the resulting lower resolution channels. Features are single pixel lookups in the aggregated channels. Boosting is used to learn decision trees over these features (pixels) to distinguish object from background. With the appropriate choice of channels and careful attention to design, ACF achieves stateoftheart performance in pedestrian detection.</span></div>



<div class="txt" style="position:absolute; height:1056px; width:422px; left:52px; top:12801px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">channels </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C </span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">¼ </span><span id="f4" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">V</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ð</span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">I</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Þ</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, sum every block of pixels in </span><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">C</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">, and smooth the resulting lower resolution channels. Features are single pixel lookups in the aggregated channels. Boosting is used to train and combine decision trees over these features (pixels) to distinguish object from background and a multiscale slidingwindow approach is employed. With the appropriate choice of channels and careful attention to design, ACF achieves stateoftheart performance in pedestrian detection. <br><br>Channels. ACF uses the same channels as [39]: normalized gradient magnitude, histogram of oriented gradients (six channels), and LUV color channels. Prior to computing the 10 channels, I is smoothed with a [1 2 1]/4 ﬁlter. The channels are divided into 4 Â 4 blocks and pixels in each block are summed. Finally the channels are smoothed, again with a [1 2 1]/4 ﬁlter. For 640 Â 480 images, computing the channels runs at over 100 fps on a modern PC. The code is optimized but runs on a single CPU; further gains could be obtained using multiple cores or a GPU as in [30]. <br><br>Pyramid. Computation of feature pyramids at octavespaced scale intervals runs at 75 fps on 640 Â 480 images. Meanwhile, computing exact feature pyramids with eight scales per octave slows to 15 fps, precluding realtime detection. In contrast, our fast pyramid construction (see Section 5) with seven of eight scales per octave approximated runs at nearly 50 fps. <br><br>Detector. For pedestrian detection, AdaBoost [69] is used to train and combine 2,048 depthtwo trees over the 128 Á 64 Á 10=16 ¼ 5;120 candidate features (channel pixel lookups) in each 128 Â 64 window. Training with multiple rounds of bootstrapping takes 10 minutes (a parallel implementation reduces this to 3 minutes). The detector has a step size of four pixels and eight scales per octave. For 640 Â 480 images, the complete system, including fast pyramid construction and slidingwindow detection, runs at over 30 fps allowing for realtime uses (with exact feature pyramids the detector slows to 12 fps). <br><br>Code. Code for the ACF framework is available online.4 For more details on the channels and detector used in ACF, including exact parameter settings and training framework, we refer users to the source code. <br><br>Accuracy. We report accuracy of ACF with exact and fast feature pyramids in Table 1. Following the methodology of [31], we summarize performance using the logaverage miss rate (MR) between 10À2 and 100 false positives per image. Results are reported on four pedestrian data sets: INRIA [21], Caltech [31], TUDBrussels [36] and ETH [37].</span></div>














































<div class="txt" style="position:absolute; left:76px; top:13921px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">4. Code: http://vision.ucsd.edu/ pdollar/toolbox/doc/index.html.</span></div>
<div class="txt" style="position:absolute; height:458px; width:409px; left:578px; top:12802px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">MRs for 16 competing methods are shown. ACF outperforms competing approaches on nearly all datasets. When averaged over the four data sets, the MR of ACF is 40 percent with exact feature pyramids and 41 percent with fast feature pyramids, a negligible difference, demonstrating the effectiveness of our approach. <br><br>Speed. MR versus speed for numerous detectors is shown in Fig. 10. ACF with fast feature pyramids runs at 32 fps. The only two faster approaches are Crosstalk cascades [40] and the VeryFast detector from Benenson et al. [30]. Their additional speedups are based on improved cascade strategies and combining multiresolution models with a GPU implementation, respectively, and are orthogonal to the gains achieved by using approximate multiscale features. Indeed, all the detectors that run at 5 fps and higher exploit the power law governing feature scaling. <br><br>Pyramid parameters. Detection performance on INRIA [21] with fast feature pyramids under varying settings is shown in Fig. 11. The key result is given in Fig. 11a: when approximating seven of eight scales per octave, the MR for ACF is 0:169 which is virtually identical to the MR of 0:166 obtained</span></div>




















<div class="txt" style="position:absolute; left:794px; top:13320px;"><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">TABLE 1</span></div>
<div class="txt" style="position:absolute; left:620px; top:13340px;"><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">MRs of Leading Approaches for Pedestrian Detection</span></div>
<div class="txt" style="position:absolute; left:757px; top:13360px;"><span id="f7" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">on Four Data Sets</span></div>
<div class="txt" style="position:absolute; height:36px; width:435px; left:578px; top:13885px;"><span id="f8" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">For ICF and ACF exact and approximate detection results are shown with only small differences between them. For the latest pedestrian detection results please see [32].</span></div>


<div style="position:absolute; left:0px; top:13980px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:14000px;" width="1129" height="1542" src="page10.png">
<div class="txt" style="position:absolute; left:52px; top:14048px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f8" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:14051px;"><span id="f7" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1541</span></div>
<div class="txt" style="position:absolute; height:108px; width:481px; left:52px; top:14271px;"><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 9. (a) A standard pipeline for performing multiscale detection is to create a densely sampled feature pyramid. (b) Viola and Jones [27] used simple shift and scale invariant features, allowing a detector to be placed at any location and scale without relying on a feature pyramid. (c) ICF can use a hybrid approach of constructing an octavespaced feature pyramid followed by approximating detector responses within half an octave of each pyramid level.</span></div>






<div class="txt" style="position:absolute; height:160px; width:390px; left:52px; top:14417px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">using the exact feature pyramid. Even approximating 15 of every 16 scales increases MR only somewhat. Constructing the channels without correcting for power law scaling, or using an incorrect value of , results in markedly decreased performance, see Fig. 11b. Finally, we observe that at least eight scales per octave must be used for good performance (Fig. 11c), making the proposed scheme crucial for achieving detection results that are both fast and accurate.</span></div>







<div class="txt" style="position:absolute; height:347px; width:409px; left:52px; top:14624px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">6.2 Integral Channel Features Integral channel features [29] are a precursor to the ACF framework described in Section 6.1. Both ACF and ICF use the same channel features and boosted classiﬁers; the key difference between the two frameworks is that ACF uses pixel lookups in aggregated channels as features while ICF uses sums over rectangular channel regions (computed efﬁciently with integral images). <br><br>Accuracy of ICF with exact and fast feature pyramids is shown in Table 1. ICF achieves stateoftheart results: inferior to ACF but otherwise outperforming most competing approaches. The MR of ICF averaged over the four data sets is 42 percent with exact feature pyramids and 45 percent with fast feature pyramids. The gap of 3 percent is larger than the 1 percent gap for ACF but still small. With fast feature pyramids ICF runs at 16 fps, see Fig. 10. ICF is slower</span></div>















<div class="txt" style="position:absolute; height:573px; width:403px; left:578px; top:14094px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">than ACF due to construction of integral images and more expensive features (rectangular sums computed via integral images versus single pixel lookups). For more details on ICF, see [29], [39]. The variant tested here uses identical channels to ACF. <br><br>Detection performance with fast feature pyramids under varying settings is shown in Fig. 12. The plots mirror the results shown in Fig. 11 for ACF. The key result is given in Fig. 12a: when approximating seven of eight scales per octave, the MR for ICF is 2 percent worse than the MR obtained with exact feature pyramids. <br><br>The ICF framework allows for an alternate application of the power law governing feature scaling: instead of rescaling channels as discussed in Section 5, one can instead rescale the detector. Using the notation from Section 4, rectangular channel sums (features used in ICF) can be written as AfVðIÞ, where A denotes rectangle area. As such, Eq. (4) can be applied to approximate features at nearby scales and given integral channel images computed at one scale, detector responses can be approximated at nearby scales. This operation can be implemented by rescaling the detector itself, see [39]. As the approximation degrades with increasing scale offsets, a hybrid approach is to construct an octavespaced feature pyramid followed by approximating detector responses at nearby scales, see Fig. 9. This approach was extended in [30].</span></div>

























<div class="txt" style="position:absolute; height:255px; width:396px; left:578px; top:14716px;"><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">6.3 Deformable Part Models Deformable part models from Felzenszwalb et al. [35] are an elegant approach for general object detection that have consistently achieved top results on the PASCAL VOC challenge [38]. DPMs use a variant of HOG features [21] as their image representation, followed by classiﬁcation with linear SVMs. An object model is composed of multiple parts, a root model, and optionally multiple mixture components. For details see [35]. <br><br>Recent approaches for increasing the speed of DPMs include work by Felzenszwalb et al. [44] and Pedersoli et al. [45] on cascaded and coarsetoﬁne deformable part</span></div>











<div class="txt" style="position:absolute; height:108px; width:968px; left:52px; top:15363px;"><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 10. Logaverage miss rate on the INRIA pedestrian data set [21] versus frame rate on </span><span id="f8" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">640 </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Â </span><span id="f8" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">480 </span><span id="f7" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">images for multiple detectors. Method runtimes were obtained from [31], see also [31] for citations for detectors AL. Numbers in brackets indicate MR/fps for select approaches, sorted by speed. All detectors that run at 5 fps and higher are based on our fast feature pyramids; these methods are also the most accurate. They include: (M) FPDW [39] which is our original implementation of ICF, (N) ICF [Section 6.2], (O) ACF [Section 6.1], (P) crosstalk cascades [40], and (Q) the VeryFast detector from Benenson et al. [30]. Both (P) and (Q) use the power law governing feature scaling described in this work; the additional speedups in (P) and (Q) are based on improved cascade strategies, multiresolution models and a GPU implementation, and are orthogonal to the gains achieved by using approximate multiscale features.</span></div>






<div style="position:absolute; left:0px; top:15530px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:15550px;" width="1129" height="1542" src="page11.png">
<div class="txt" style="position:absolute; left:52px; top:15601px;"><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1542</span></div>
<div class="txt" style="position:absolute; left:334px; top:15601px;"><span id="f4" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; height:90px; width:975px; left:52px; top:15880px;"><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 11. </span><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Effect of parameter setting of fast feature pyramids on the ACF detector </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[Section 6.1]. We report logaverage miss rate averaged over 25 trials on the INRIA pedestrian data set [21]. Orange diamonds denote default parameter settings: 7/8 scales approximated per octave,  % 0:17 for the normalized gradient channels, and eight scales per octave in the pyramid. (a) The MR stays relatively constant as the fraction of approximated scales increases up to 7/8 demonstrating the efﬁcacy of the proposed approach. (b) Suboptimal values of  when approximating the normalized gradient channels cause a marked decrease in performance. (c) At least eight scales per octave are necessary for good performance, making the proposed scheme crucial for achieving detection results that are both fast and accurate.</span></div>





<div class="txt" style="position:absolute; height:458px; width:416px; left:52px; top:16025px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">models, respectively. Our work is complementary as we focus on improving the speed of pyramid construction. The current bottleneck of DPMs is in the classiﬁcation stage, therefore pyramid construction accounts for only a fraction of total runtime. However, if fast feature pyramids are coupled with optimized classiﬁcation schemes [44], [45], DPMs have the potential to have more competitive runtimes. We focus on demonstrating DPMs can achieve good accuracy with fast feature pyramids and leave the coupling of fast feature pyramids and optimized classiﬁcation schemes to practitioners. <br><br>DPM code is available online [35]. We tested pretrained DPM models on the 20 PASCAL 2007 categories using exact HOG pyramids and HOG pyramids with nine of 10 scales per octave approximated using our proposed approach. Average precision (AP) scores for the two approaches, denoted DPM and DPM, respectively, are shown in Table 2. The mean AP across the 20 categories is 26.6 percent for DPMs and 24.5 percent for DPMs. Using fast HOG feature pyramids only decreased mean AP 2 percent, demonstrating the validity of the proposed approach.</span></div>




















<div class="txt" style="position:absolute; left:52px; top:16543px;"><span id="f3" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">7 C</span><span id="f3" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">ONCLUSION</span></div>
<div class="txt" style="position:absolute; height:69px; width:364px; left:52px; top:16578px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Improvements in the performance of visual recognition systems in the past decade have in part come from the realization that ﬁnely sampled pyramids of image features provide a good frontend for image analysis. It is</span></div>



<div class="txt" style="position:absolute; height:619px; width:422px; left:578px; top:16025px;"><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">widely believed that the price to be paid for improved performance is sharply increased computational costs. We have shown that this is not necessarily so. Finely sampled pyramids may be obtained inexpensively by extrapolation from coarsely sampled ones. This insight decreases computational costs substantially. <br><br>Our insight ultimately relies on the fractal structure of much of the visual world. By investigating the statistics of natural images we have demonstrated that the behavior of image features can be predicted reliably across scales. Our calculations and experiments show that this makes it possible to estimate features at a given scale inexpensively by extrapolating computations carried out at a coarsely sampled set of scales. While our results do not hold under all circumstances, for instance, on images of textures or white noise, they do hold for images typically encountered in the natural world. <br><br>In order to validate our ﬁndings we studied the performance of three endtoend object detection systems. We found that detection rates are relatively unaffected while computational costs decrease considerably. This has led to the ﬁrst detectors that operate at frame rate while using rich feature representations. <br><br>Our results are not restricted to object detection nor to visual recognition. The foundations we have developed should readily apply to other computer vision tasks where a ﬁnegrained scale sampling of features is necessary as the image processing front end.</span></div>



























<div class="txt" style="position:absolute; height:72px; width:1001px; left:52px; top:16949px;"><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Fig. 12. </span><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Effect of parameter setting of fast feature pyramids on the </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ICF </span><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">detector </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[Section 6.2]. The plots mirror the results shown in Fig. 11 for the ACF detector, although overall performance for ICF is slightly lower. (a) When approximating seven of every eight scales in the pyramid, the MR for ICF is 0:195 which is only slightly worse than the MR of 0:176 obtained using exact feature pyramids. (b) Computing approximate channels with an incorrect value of  results in decreased performance (although using a slightly larger  than predicted appears to improve results marginally). (c) Similarly to the ACF framework, at least eight scales per octave are necessary to achieve good results.</span></div>




<div style="position:absolute; left:0px; top:17080px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:17100px;" width="1129" height="1542" src="page12.png">
<div class="txt" style="position:absolute; left:52px; top:17148px;"><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f3" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:17151px;"><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1543</span></div>
<div class="txt" style="position:absolute; left:268px; top:17192px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">TABLE 2</span></div>
<div class="txt" style="position:absolute; left:91px; top:17212px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Average Precision Scores for Deformable Part Models</span></div>
<div class="txt" style="position:absolute; left:130px; top:17231px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">with Exact (DPM) and Approximate (</span><span id="f6" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">$</span><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">DPM)</span></div>
<div class="txt" style="position:absolute; left:183px; top:17251px;"><span id="f5" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">Feature Pyramids on PASCAL</span></div>
<div class="txt" style="position:absolute; left:52px; top:17467px;"><span id="f1" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">A</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">CKNOWLEDGMENTS</span></div>
<div class="txt" style="position:absolute; height:183px; width:364px; left:52px; top:17502px;"><span id="f2" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">The authors thank Peter Welinder and Rodrigo Benenson for helpful comments and suggestions. Piotr Dollar, Ron Appel, and Pietro Perona were supported by MURIONR N000141010933 and ARO/JPLNASA Stennis NAS7.03001. Ron Appel was also supported by NSERC 4204562012 and The Moore Foundation. Serge Belongie was supported by the US National Science Foundation (NSF) CAREER Grant 0448615, MURIONR N000140810638 and a Google Research Award.</span></div>








<div class="txt" style="position:absolute; left:52px; top:17731px;"><span id="f1" style="font-size:16px;vertical-align:baseline;color:rgba(34,30,31,1);">R</span><span id="f1" style="font-size:15px;vertical-align:baseline;color:rgba(34,30,31,1);">EFERENCES</span></div>
<div class="txt" style="position:absolute; left:52px; top:17764px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[1] D. Hubel and T. Wiesel, “Receptive Fields and Functional Archi-</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:17782px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">tecture of Monkey Striate Cortex,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">J. Physiology</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 195, pp. 215243, 1968.</span></div>

<div class="txt" style="position:absolute; left:52px; top:17818px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[2] C. Malsburg, “Self-Organization of Orientation Sensitive Cells in</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:17836px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">the Striate Cortex,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Biological Cybernetics</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 14, no. 2, pp. 85100, 1973.</span></div>

<div class="txt" style="position:absolute; left:52px; top:17872px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[3] L. Maffei and A. Fiorentini, “The Visual Cortex as a Spatial Fre-</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:90px; top:17890px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">quency Analyser,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Vision Research</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 13, no. 7, pp. 12551267, 1973.</span></div>

<div class="txt" style="position:absolute; left:52px; top:17926px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[4] P. Burt and E. Adelson, “The Laplacian Pyramid as a Compact</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:90px; top:17943px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Image Code,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Comm.</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 31, no. 4, pp. 532540, Apr. 1983.</span></div>

<div class="txt" style="position:absolute; left:52px; top:17979px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[5] J. Daugman, “Uncertainty Relation for Resolution in Space, Spa-</span></div>
<div class="txt" style="position:absolute; height:36px; width:454px; left:90px; top:17997px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">tial Frequency, and Orientation Optimized by TwoDimensional Visual Cortical Filters,” J. Optical Soc. Am. A: Optics, Image Science, and Vision, vol. 2, pp. 11601169, 1985.</span></div>


<div class="txt" style="position:absolute; left:52px; top:18051px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[6] J. Koenderink and A. Van Doorn, “Representation of Local Geom-</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:90px; top:18069px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">etry in the Visual System,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Biological Cybernetics</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 55, no. 6, pp. 367375, 1987.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18105px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[7] D.J. Field, “Relations between the Statistics of Natural Images</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:90px; top:18123px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">and the Response Properties of Cortical Cells,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">J. Optical Soc. Am. A: Optics, Image Science, and Vision, vol. 4, pp. 23792394, 1987.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18159px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[8] S. Mallat, “A Theory for Multiresolution Signal Decomposition:</span></div>
<div class="txt" style="position:absolute; height:18px; width:409px; left:90px; top:18177px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">The Wavelet Representation,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 11, no. 7, pp. 647693, July 1989.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18213px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[9] P. Vaidyanathan, “Multirate Digital Filters, Filter Banks, Poly-</span></div>
<div class="txt" style="position:absolute; height:18px; width:390px; left:90px; top:18230px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">phase Networks, and Applications: A Tutorial,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 78, no. 1, pp. 5693, Jan. 1990.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18266px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[10] M. Vetterli, “A Theory of Multirate Filter Banks,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans.</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:90px; top:18284px;"><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Acoustics, Speech and Signal Processing</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 35, no. 3, pp. 356372, Mar. 1987.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18320px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[11] E. Simoncelli and E. Adelson, “Noise Removal via Bayesian</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:18338px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Wavelet Coring,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Int’l Conf. Image Processing (ICIP)</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 1, 1996.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18374px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[12] W.T. Freeman and E.H. Adelson, “The Design and Use of Steer-</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:18392px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">able Filters,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Pattern Analysis and Machine Intelligence</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 13, no. 9, pp. 891906, Sept. 1991.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18428px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[13] J. Malik and P. Perona, “Preattentive Texture Discrimination with</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:90px; top:18446px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Early Vision Mechanisms,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">J. Optical Soc. Am. A</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 7, pp. 923932, May 1990.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18482px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[14] D. Jones and J. Malik, “Computational Framework for Determin-</span></div>
<div class="txt" style="position:absolute; height:18px; width:409px; left:90px; top:18499px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ing Stereo Correspondence from a Set of Linear Spatial Filters,”</span></div>Image and Vision Computing, vol. 10, no. 10, pp. 699708, 1992.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18535px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[15] E. Adelson and J. Bergen, “Spatiotemporal Energy Models for the</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:18553px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Perception of Motion,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">J. Optical Soc. Am. A</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 2, no. 2, pp. 284299, 1985.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17192px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[16] Y. Weiss and E. Adelson, “A Uniﬁed Mixture Framework for</span></div>
<div class="txt" style="position:absolute; height:36px; width:416px; left:616px; top:17209px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Motion Segmentation: Incorporating Spatial Coherence and Estimating the Number of Models,” Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 1996.</span></div>


<div class="txt" style="position:absolute; left:578px; top:17263px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[17] L. Itti, C. Koch, and E. Niebur, “A Model of Saliency-Based Visual</span></div>
<div class="txt" style="position:absolute; height:18px; width:442px; left:616px; top:17281px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Attention for Rapid Scene Analysis,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 20, no. 11, pp. 12541259, Nov. 1998.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17317px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[18] P. Perona and J. Malik, “Detecting and Localizing Edges Com-</span></div>
<div class="txt" style="position:absolute; height:18px; width:461px; left:616px; top:17335px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">posed of Steps, Peaks and Roofs,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Third IEEE Int’l Conf. Computer Vision (ICCV), 1990.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17371px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[19] M. Lades, J. Vorbruggen, J. Buhmann, J. Lange, C. von der</span></div>
<div class="txt" style="position:absolute; height:36px; width:422px; left:616px; top:17389px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Malsburg, R. Wurtz, and W. Konen, “Distortion Invariant Object Recognition in the Dynamic Link Architecture,” IEEE Trans. Computers, vol. 42, no. 3, pp. 300311, Mar. 1993.</span></div>


<div class="txt" style="position:absolute; left:578px; top:17443px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[20] D.G. Lowe, “Object Recognition from Local Scale-Invariant</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:616px; top:17460px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Features,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Seventh IEEE Int’l Conf. Computer Vision (ICCV)</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, 1999.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17496px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[21] N. Dalal and B. Triggs, “Histograms of Oriented Gradients for</span></div>
<div class="txt" style="position:absolute; height:18px; width:416px; left:616px; top:17514px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Human Detection,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2005.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17550px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[22] R. De Valois, D. Albrecht, and L. Thorell, “Spatial Frequency</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:616px; top:17568px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Selectivity of Cells in Macaque Visual Cortex,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Vision Research</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 22, no. 5, pp. 545559, 1982.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17604px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[23] Y. LeCun, P. Haffner, L. Bottou, and Y. Bengio, “Gradient-Based</span></div>
<div class="txt" style="position:absolute; height:18px; width:422px; left:616px; top:17622px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Learning Applied to Document Recognition,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 86, no. 11, pp. 22782324, Nov. 1998.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17658px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[24] M. Riesenhuber and T. Poggio, “Hierarchical Models of Object</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:616px; top:17676px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Recognition in Cortex,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Nature Neuroscience</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 2, pp. 10191025, 1999.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17711px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[25] D.G. Lowe, “Distinctive Image Features from Scale-Invariant Key-</span></div>
<div class="txt" style="position:absolute; left:616px; top:17729px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">points,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Int’l J. Computer Vision</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 60, no. 2, pp. 91-110, 2004.</span></div>
<div class="txt" style="position:absolute; left:578px; top:17747px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[26] A. Krizhevsky, I. Sutskever, and G. Hinton, “Imagenet Classiﬁca-</span></div>
<div class="txt" style="position:absolute; height:18px; width:409px; left:616px; top:17765px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">tion with Deep Convolutional Neural Networks,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Advances in Neural Information Processing Systems (NIPS), 2012.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17801px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[27] P. Viola and M. Jones, “Rapid Object Detection Using a Boosted</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:616px; top:17819px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Cascade of Simple Features,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2001.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17855px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[28] P. Viola, M. Jones, and D. Snow, “Detecting Pedestrians Using</span></div>
<div class="txt" style="position:absolute; height:18px; width:422px; left:616px; top:17873px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Patterns of Motion and Appearance,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Int’l J. Computer Vision</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 63, no. 2, pp. 153161, 2005.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17908px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[29] P. Doll</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ar, Z. Tu, P. Perona, and S. Belongie, “Integral Channel</span></div>
<div class="txt" style="position:absolute; left:616px; top:17927px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Features,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. British Machine Vision Conf. (BMVC)</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, 2009.</span></div>
<div class="txt" style="position:absolute; left:578px; top:17945px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[30] R. Benenson, M. Mathias, R. Timofte, and L. Van Gool,</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:616px; top:17963px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">“Pedestrian Detection at 100 Frames per Second,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2012.</span></div>

<div class="txt" style="position:absolute; left:578px; top:17998px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[31] P. Dolla</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">r, C. Wojek, B. Schiele, and P. Perona, “Pedestrian Detec-</span></div>
<div class="txt" style="position:absolute; height:18px; width:461px; left:616px; top:18016px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">tion: An Evaluation of the State of the Art,”</span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 34, no. 4, pp. 743–761, 2012.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18052px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[32] www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/,</span></div>
<div class="txt" style="position:absolute; left:616px; top:18070px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">2014.</span></div>
<div class="txt" style="position:absolute; left:578px; top:18088px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[33] D.L. Ruderman and W. Bialek, “Statistics of Natural Images: Scal-</span></div>
<div class="txt" style="position:absolute; height:18px; width:468px; left:616px; top:18106px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ing in the Woods,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Physical Rev. Letters</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 73, no. 6, pp. 814817, Aug. 1994.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18142px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[34] E. Switkes, M. Mayer, and J. Sloan, “Spatial Frequency Analysis of</span></div>
<div class="txt" style="position:absolute; height:36px; width:429px; left:616px; top:18160px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">the Visual Environment: Anisotropy and the Carpentered Environment Hypothesis,” Vision Research, vol. 18, no. 10, pp. 13931399, 1978.</span></div>


<div class="txt" style="position:absolute; left:578px; top:18214px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[35] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan,</span></div>
<div class="txt" style="position:absolute; height:35px; width:461px; left:616px; top:18232px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">“Object Detection with Discriminatively Trained Part Based Models,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 32, no. 9, pp. 16271645, Sept. 2010.</span></div>


<div class="txt" style="position:absolute; left:578px; top:18285px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[36] C. Wojek, S. Walk, and B. Schiele, “Multi-Cue Onboard Pedestrian</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:616px; top:18303px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detection,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2009.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18339px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[37] A. Ess, B. Leibe, and L. Van Gool, “Depth and Appearance for</span></div>
<div class="txt" style="position:absolute; height:18px; width:461px; left:616px; top:18357px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Mobile Scene Analysis,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE 11th Int’l Conf. Computer Vision (ICCV), 2007.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18393px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[38] M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, and A.</span></div>
<div class="txt" style="position:absolute; height:36px; width:455px; left:616px; top:18411px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Zisserman, “The PASCAL Visual Object Classes (VOC) Challenge,” Int’l J. Computer Vision, vol. 88, no. 2, pp. 303338, June 2010.</span></div>


<div class="txt" style="position:absolute; left:578px; top:18464px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[39] P. Dolla</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">r, S. Belongie, and P. Perona, “The Fastest Pedestrian</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:616px; top:18483px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detector in the West,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. British Machine Vision Conf. (BMVC)</span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, 2010.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18518px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[40] P. Doll</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ar, R. Appel, and W. Kienzle, “Crosstalk Cascades for</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:616px; top:18536px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">FrameRate Pedestrian Detection,” </span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. 12th European Conf. Computer Vision (ECCV), 2012.</span></div>

<div style="position:absolute; left:0px; top:18630px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:18650px;" width="1129" height="1542" src="page13.png">
<div class="txt" style="position:absolute; left:52px; top:18701px;"><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1544</span></div>
<div class="txt" style="position:absolute; left:334px; top:18701px;"><span id="f5" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 8, AUGUST 2014</span></div>
<div class="txt" style="position:absolute; left:52px; top:18742px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[41] T. Lindeberg, “Scale-Space for Discrete Signals,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Pat-</span></div>
<div class="txt" style="position:absolute; height:18px; width:442px; left:90px; top:18759px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">tern Analysis and Machine Intelligence</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 12, no. 3, pp. 234254, Mar. 1990.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18795px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[42] J.L. Crowley, O. Riff, and J.H. Piater, “Fast Computation of Char-</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:90px; top:18813px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">acteristic Scale Using a HalfOctave Pyramid,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Fourth Int’l Conf. ScaleSpace Theories in Computer Vision, 2002.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18849px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[43] R.S. Eaton, M.R. Stevens, J.C. McBride, G.T. Foil, and M.S. Snorra-</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:18867px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">son, “A Systems View of Scale Space,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Int’l Conf. Computer Vision Systems (ICVS), 2006.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18903px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[44] P. Felzenszwalb, R. Girshick, and D. McAllester, “Cascade Object</span></div>
<div class="txt" style="position:absolute; height:18px; width:409px; left:90px; top:18921px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detection with Deformable Part Models,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2010.</span></div>

<div class="txt" style="position:absolute; left:52px; top:18957px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[45] M. Pedersoli, A. Vedaldi, and J. Gonzalez, “A Coarse-to-Fine</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:90px; top:18975px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Approach for Fast Deformable Object Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2011.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19010px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[46] C.H. Lampert, M.B. Blaschko, and T. Hofmann, “Efﬁcient Sub-</span></div>
<div class="txt" style="position:absolute; height:36px; width:454px; left:90px; top:19028px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">window Search: A Branch and Bound Framework for Object Localization,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 31, no. 12, pp. 21292142, Dec. 2009.</span></div>


<div class="txt" style="position:absolute; left:52px; top:19082px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[47] L. Bourdev and J. Brandt, “Robust Object Detection via Soft</span></div>
<div class="txt" style="position:absolute; height:18px; width:442px; left:90px; top:19100px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Cascade,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2005.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19136px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[48] C. Zhang and P. Viola, “Multiple-Instance Pruning for Learning</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:90px; top:19154px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Efﬁcient Cascade Detectors,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Advances in Neural Information Processing Systems (NIPS), 2007.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19185px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[49] J. S</span><span id="f3" style="font-size:14px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ochman and J. Matas, “Waldboost—Learning for Time Con-</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:90px; top:19208px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">strained Sequential Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2005.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19244px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[50] H. Masnadi-Shirazi and N. Vasconcelos, “High Detection-Rate</span></div>
<div class="txt" style="position:absolute; height:17px; width:435px; left:90px; top:19262px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Cascades for RealTime Object Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE 11th Int’l Conf. Computer Vision (ICCV), 2007.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19297px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[51] F. Fleuret and D. Geman, “Coarse-To-Fine Face Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Int’l J.</span></div>
<div class="txt" style="position:absolute; left:90px; top:19315px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Computer Vision</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 41, no. 1/2, pp. 85-107, 2001.</span></div>
<div class="txt" style="position:absolute; left:52px; top:19333px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[52] P. Felzenszwalb and D. Huttenlocher, “Efﬁcient Matching of Pic-</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:19351px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">torial Structures,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2000.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19387px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[53] C. Papageorgiou and T. Poggio, “A Trainable System for Object</span></div>
<div class="txt" style="position:absolute; left:90px; top:19405px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Int’l J. Computer Vision</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 38, no. 1, pp. 15-33, 2000.</span></div>
<div class="txt" style="position:absolute; left:52px; top:19423px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[54] M. Weber, M. Welling, and P. Perona, “Unsupervised Learning of</span></div>
<div class="txt" style="position:absolute; height:18px; width:409px; left:90px; top:19441px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Models for Recognition,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. European Conf. Computer Vision (ECCV), 2000.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19477px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[55] S. Agarwal and D. Roth, “Learning a Sparse Representation for</span></div>
<div class="txt" style="position:absolute; height:18px; width:422px; left:90px; top:19495px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Object Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. European Conf. Computer Vision (ECCV)</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, 2002.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19531px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[56] R. Fergus, P. Perona, and A. Zisserman, “Object Class Recognition</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:90px; top:19548px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">by Unsupervised ScaleInvariant Learning,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2003.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19584px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[57] B. Leibe, A. Leonardis, and B. Schiele, “Robust Object Detection</span></div>
<div class="txt" style="position:absolute; height:18px; width:442px; left:90px; top:19602px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">with Interleaved Categorization and Segmentation,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Int’l J. Computer Vision, vol. 77, no. 13, pp. 259289, May 2008.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19638px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[58] C. Gu, J.J. Lim, P. Arbela</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ez, and J. Malik, “Recognition Using</span></div>
<div class="txt" style="position:absolute; height:18px; width:442px; left:90px; top:19656px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Regions,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2009.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19692px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[59] B. Alexe, T. Deselaers, and V. Ferrari, “What Is an Object?” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc.</span></div>
<div class="txt" style="position:absolute; left:90px; top:19710px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Conf. Computer Vision and Pattern Recognition (CVPR)</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, 2010.</span></div>
<div class="txt" style="position:absolute; left:52px; top:19727px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[60] C. Wojek, G. Dorko</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, A. Schulz, and B. Schiele, “Sliding-Windows</span></div>
<div class="txt" style="position:absolute; height:18px; width:435px; left:90px; top:19746px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">for Rapid Object Class Localization: A Parallel Technique,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. 30th DAGM Symp. Pattern Recognition, 2008.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19782px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[61] L. Zhang and R. Nevatia, “Efﬁcient Scan-Window Based Object</span></div>
<div class="txt" style="position:absolute; height:17px; width:409px; left:90px; top:19800px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detection Using GPGPU,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. Workshop Visual Computer Vision on GPU’s (CVGPU), 2008.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19835px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[62] B. Bilgic, “Fast Human Detection with Cascaded Ensembles,”</span></div>
<div class="txt" style="position:absolute; left:90px; top:19853px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">master’s thesis, MIT, Feb. 2010.</span></div>
<div class="txt" style="position:absolute; left:52px; top:19871px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[63] Q. Zhu, S. Avidan, M. Yeh, and K. Cheng, “Fast Human Detection</span></div>
<div class="txt" style="position:absolute; height:18px; width:416px; left:90px; top:19889px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Using a Cascade of Histograms of Oriented Gradients,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2006.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19925px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[64] F.M. Porikli, “Integral Histogram: A Fast Way to Extract Histo-</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:90px; top:19943px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">grams in Cartesian Spaces,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2005.</span></div>

<div class="txt" style="position:absolute; left:52px; top:19979px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[65] A. Ess, B. Leibe, K. Schindler, and L. Van Gool, “Robust Multi-Per-</span></div>
<div class="txt" style="position:absolute; height:18px; width:454px; left:90px; top:19997px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">son Tracking from a Mobile Platform,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 31, no. 10, pp. 18311846, Oct. 2009.</span></div>

<div class="txt" style="position:absolute; left:52px; top:20033px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[66] M. Bajracharya, B. Moghaddam, A. Howard, S. Brennan, and L.H.</span></div>
<div class="txt" style="position:absolute; height:35px; width:435px; left:90px; top:20051px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Matthies, “A Fast StereoBased System for Detecting and Tracking Pedestrians from a Moving Vehicle,” Int’l J. Robotics Research, vol. 28, pp. 14661485, 2009.</span></div>


<div class="txt" style="position:absolute; left:578px; top:18742px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[67] D.L. Ruderman, “The Statistics of Natural Images,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Network: Com-</span></div>
<div class="txt" style="position:absolute; left:616px; top:18759px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">putation in Neural Systems</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 5, no. 4, pp. 517-548, 1994.</span></div>
<div class="txt" style="position:absolute; left:578px; top:18777px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[68] S.G. Ghurye, “A Characterization of the Exponential Function,”</span></div>
<div class="txt" style="position:absolute; left:616px; top:18795px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">The Am. Math. Monthly</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 64, no. 4, pp. 255-257, 1957.</span></div>
<div class="txt" style="position:absolute; left:578px; top:18813px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[69] J. Friedman, T. Hastie, and R. Tibshirani, “Additive Logistic</span></div>
<div class="txt" style="position:absolute; height:18px; width:442px; left:616px; top:18831px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Regression: A Statistical View of Boosting,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Annals of Statistics</span><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">, vol. 38, no. 2, pp. 337374, 2000.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18867px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[70] P. Sabzmeydani and G. Mori, “Detecting Pedestrians by Learning</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:616px; top:18885px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Shapelet Features,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2007.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18921px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[71] Z. Lin and L.S. Davis, “A Pose-Invariant Descriptor for Human</span></div>
<div class="txt" style="position:absolute; height:18px; width:422px; left:616px; top:18939px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detection and Segmentation,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. 10th European Conf. Computer Vision (ECCV), 2008.</span></div>

<div class="txt" style="position:absolute; left:578px; top:18975px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[72] S. Maji, A. Berg, and J. Malik, “Classiﬁcation Using Intersection</span></div>
<div class="txt" style="position:absolute; height:17px; width:429px; left:616px; top:18993px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Kernel SVMs Is Efﬁcient,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2008.</span></div>

<div class="txt" style="position:absolute; left:578px; top:19028px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[73] X. Wang, T.X. Han, and S. Yan, “An HOG-LBP Human Detector</span></div>
<div class="txt" style="position:absolute; height:18px; width:448px; left:616px; top:19046px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">with Partial Occlusion Handling,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Int’l Conf. Computer Vision (ICCV), 2009.</span></div>

<div class="txt" style="position:absolute; left:578px; top:19082px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[74] C. Wojek and B. Schiele, “A Performance Evaluation of Single and</span></div>
<div class="txt" style="position:absolute; height:18px; width:416px; left:616px; top:19100px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">MultiFeature People Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. 30th DAGM Symp. Pattern Recognition (DAGM), 2008.</span></div>

<div class="txt" style="position:absolute; left:578px; top:19136px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[75] W. Schwartz, A. Kembhavi, D. Harwood, and L. Davis, “Human</span></div>
<div class="txt" style="position:absolute; height:18px; width:429px; left:616px; top:19154px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Detection Using Partial Least Squares Analysis,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE 12th Int’l Conf. Computer Vision (ICCV), 2009.</span></div>

<div class="txt" style="position:absolute; left:578px; top:19190px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[76] S. Walk, N. Majer, K. Schindler, and B. Schiele, “New Features and</span></div>
<div class="txt" style="position:absolute; height:18px; width:409px; left:616px; top:19208px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Insights for Pedestrian Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2010.</span></div>

<div class="txt" style="position:absolute; left:578px; top:19244px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">[77] D. Park, D. Ramanan, and C. Fowlkes, “Multiresolution Models</span></div>
<div class="txt" style="position:absolute; height:17px; width:429px; left:616px; top:19262px;"><span id="f1" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">for Object Detection,” </span><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Proc. 11th European Conf. Computer Vision (ECCV), 2010.</span></div>

<div class="txt" style="position:absolute; height:180px; width:318px; left:738px; top:19316px;"><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Piotr Dolla</span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);"></span><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">r </span><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">received the master’s degree in computer science from Harvard University in 2002 and the PhD degree from the University of California, San Diego in 2007. He joined the Computational Vision Lab at the California Institute of Technology Caltech as a postdoctoral fellow in 2007. Upon being promoted to a senior postdoctoral fellow he realized it was time to move on, and in 2011, he joined the Interactive Visual Media Group at Microsoft Research, Redmond, Washington, where he currently</span></div>










<div class="txt" style="position:absolute; height:54px; width:461px; left:578px; top:19514px;"><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">resides. He has worked on object detection, pose estimation, boundary learning, and behavior recognition. His general interests include machine learning and pattern recognition, and their application to computer vision.</span></div>



<div class="txt" style="position:absolute; height:179px; width:325px; left:738px; top:19624px;"><span id="f4" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Ron Appel </span><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">received the bachelor’s and master’s degrees in electrical and computer engineering from the University of Toronto in 2006 and 2008, respectively. He is working toward the PhD degree in the Computational VisionLab at the California Institute of Technology, Caltech, where he currently holds an NSERC Graduate Award. He cofounded ViewGenie Inc., a company specializing in intelligent image processing and search. His research interests include machine learning, visual object detection, and</span></div>










<div class="txt" style="position:absolute; left:578px; top:19821px;"><span id="f5" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">algorithmic optimization.</span></div>
<div style="position:absolute; left:0px; top:20180px; width:1129px; height:20px;"><img src="http://www.mdtserver.com/s21/sepfree.png" width="100%"> </div><img id="background" style="position:absolute; left:0px; top:20200px;" width="1129" height="1542" src="page14.png">
<div class="txt" style="position:absolute; left:52px; top:20248px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">DOLLA</span><span id="f4" style="font-size:12px;vertical-align:super;color:rgba(34,30,31,1);"></span><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">R ET AL.: FAST FEATURE PYRAMIDS FOR OBJECT DETECTION</span></div>
<div class="txt" style="position:absolute; left:1049px; top:20251px;"><span id="f3" style="font-size:12px;vertical-align:baseline;color:rgba(34,30,31,1);">1545</span></div>
<div class="txt" style="position:absolute; height:179px; width:332px; left:212px; top:20291px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Serge Belongie </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">received the BS (with honor) in electrical engineering from the California Institute of Technology, Caltech in 1995 and the PhD degree in electrical engineering and computer science from the University of California at Berkeley in 2000. While at the University of California at Berkeley, his research was supported by the US National Science Foundation (NSF) Graduate Research Fellowship. From 2001 to 2013, he was a professor in the Department of Computer Science and Engineering at the University of Cal</span></div>










<div class="txt" style="position:absolute; height:126px; width:468px; left:52px; top:20488px;"><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">ifornia, San Diego (UCSD). He is currently a professor at Cornell NYC Tech and the Cornell Computer Science Department, Ithaca, New York. His research interests include computer vision, machine learning, crowdsourcing, and humanintheloop computing. He is also a cofounder of several companies including Digital Persona, Anchovi Labs (acquired by Dropbox) and Orpix. He is a recipient of the US National Science Foundation (NSF) CAREER Award, the Alfred P. Sloan Research Fellowship, and the MIT Technology Review “Innovators Under 35” Award.</span></div>







<div class="txt" style="position:absolute; height:179px; width:318px; left:738px; top:20291px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">Pietro Perona </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">received the graduate degree in electrical engineering from the Universita di Padova in 1985 and the PhD degree in electrical engineering and computer science from the University of California at Berkeley in 1990. After a postdoctoral fellowship at MIT in 19901991 he joined the faculty of the California Institute of Technology, Caltech in 1991, where he is now an Allen E. Puckett professor of electrical engineering and computation and neural systems. His current interests include</span></div>










<div class="txt" style="position:absolute; height:90px; width:474px; left:578px; top:20488px;"><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">visual recognition, modeling vision in biological systems, modeling and measuring behavior, and Visipedia. He has worked on anisotropic diffusion, multiresolutionmultiorientation ﬁltering, human texture perception and segmentation, dynamic vision, grouping, analysis of human motion, recognition of object categories, and modeling visual search.</span></div>





$$$
<div class="txt" style="position:absolute; left:578px; top:20652px;"><span id="f2" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">please visit our Digital Library at </span><span id="f3" style="font-size:14px;vertical-align:baseline;color:rgba(34,30,31,1);">www.computer.org/publications/dlib.</span></div>
</body></html>